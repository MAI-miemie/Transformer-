{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac385fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16ace4ff1d0>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read in data\n",
    "df = pd.read_csv(\"English_Cn_Name_Corpus（48W）.txt\", header=None, names=[\"name\"], skiprows=2)\n",
    "names = df[\"name\"].values\n",
    "\n",
    "# Compute character frequency\n",
    "chars = [list(name) for name in names]\n",
    "chars_flatten = list(itertools.chain(*chars))\n",
    "freq = collections.Counter(chars_flatten)\n",
    "freq = pd.DataFrame(freq.items(), columns=[\"char\", \"freq\"])\n",
    "freq = freq.sort_values(by=\"freq\", ascending=False)\n",
    "\n",
    "# Frequency distribution\n",
    "char_rank = np.arange(freq.shape[0])\n",
    "char_freq = freq[\"freq\"].values\n",
    "plt.plot(char_rank, char_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7aaca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data\n",
    "dict_size = 50\n",
    "charset_size = dict_size + 1  # for EOS\n",
    "dict = list(freq[\"char\"].values[:dict_size])\n",
    "dict_set = set(dict)\n",
    "dat = list(filter(lambda name: set(name).issubset(dict_set), names))\n",
    "\n",
    "# One-hot encoding\n",
    "def char2index(char):\n",
    "    return dict.index(char)\n",
    "\n",
    "def name2index(name):\n",
    "    return [char2index(char) for char in name]\n",
    "\n",
    "def char2tensor(char):\n",
    "    tensor = torch.zeros(1, charset_size)\n",
    "    tensor[0, char2index(char)] = 1\n",
    "    return tensor\n",
    "\n",
    "def name2tensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, charset_size)\n",
    "    for i, char in enumerate(name):\n",
    "        tensor[i, 0, char2index(char)] = 1\n",
    "    return tensor\n",
    "\n",
    "def names2tensor(names):\n",
    "    n = len(names)\n",
    "    lens = [len(name) for name in names]\n",
    "    max_len = np.max(lens)\n",
    "    tensor = torch.zeros(max_len, n, charset_size)\n",
    "    target = torch.zeros(max_len, n, dtype=int) + charset_size - 1  # 开始全都是50，代表停止符\n",
    "    for i in range(n):\n",
    "        name = names[i]             # the i-th name\n",
    "        for j in range(len(name)):  # the j-th character in the name\n",
    "            tensor[j, i, char2index(name[j])] = 1\n",
    "            if j < len(name) - 1:\n",
    "                target[j, i] = char2index(name[j + 1])\n",
    "    return tensor, np.array(lens), target\n",
    "\n",
    "char2index(\"斯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764e46bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 17]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2index(\"斯基\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6f59bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2tensor(\"斯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a27e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2tensor(\"斯基\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6881233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]),\n",
       " array([2, 3]),\n",
       " tensor([[17, 28],\n",
       "         [50,  7],\n",
       "         [50, 50]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names2tensor([\"斯基\", \"斯诺夫\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b323584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, input_size)\n",
    "        self.o2o = nn.Linear(hidden_size + input_size, input_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = torch.relu(self.i2h(input_combined))\n",
    "        output = torch.relu(self.i2o(input_combined))\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.logsoftmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a752a4ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8769, -3.8379, -4.0937, -3.9832, -4.0277, -3.9607, -3.9372, -3.8446,\n",
       "         -4.0200, -3.9447, -4.0265, -3.9387, -3.9561, -4.0500, -3.8296, -4.0310,\n",
       "         -3.8942, -3.9387, -3.9640, -3.9387, -3.9396, -3.8499, -3.8135, -3.9969,\n",
       "         -4.0112, -3.9483, -3.8273, -3.9290, -4.0002, -3.9387, -4.0159, -4.0057,\n",
       "         -3.9382, -3.8956, -3.8394, -3.7901, -3.9827, -3.9032, -4.0231, -3.9341,\n",
       "         -3.8340, -3.8574, -3.9309, -3.9740, -3.9267, -3.8872, -3.8140, -3.9586,\n",
       "         -3.8816, -3.9624, -3.9456]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 64\n",
    "rnn = RNN(charset_size, n_hidden)\n",
    "input = name2tensor(\"斯基\")\n",
    "hidden = rnn.init_hidden(batch_size=1)\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e82b8c1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch 0, loss = 3.9328794479370117\n",
      "epoch 0, batch 10, loss = 3.537919521331787\n",
      "epoch 0, batch 20, loss = 3.2228903770446777\n",
      "epoch 0, batch 30, loss = 3.178758144378662\n",
      "epoch 0, batch 40, loss = 3.1477208137512207\n",
      "epoch 0, batch 50, loss = 3.123739719390869\n",
      "epoch 0, batch 60, loss = 3.138552188873291\n",
      "epoch 0, batch 70, loss = 3.149634599685669\n",
      "epoch 0, batch 80, loss = 3.1343209743499756\n",
      "epoch 0, batch 90, loss = 3.101452350616455\n",
      "epoch 0, batch 100, loss = 3.0893895626068115\n",
      "epoch 0, batch 110, loss = 3.0961766242980957\n",
      "epoch 0, batch 120, loss = 3.074568748474121\n",
      "epoch 0, batch 130, loss = 3.009594202041626\n",
      "epoch 0, batch 140, loss = 3.0292439460754395\n",
      "epoch 0, batch 150, loss = 3.004626512527466\n",
      "epoch 0, batch 160, loss = 3.0277841091156006\n",
      "epoch 0, batch 170, loss = 3.005244016647339\n",
      "epoch 0, batch 180, loss = 2.9814088344573975\n",
      "epoch 0, batch 190, loss = 2.9858202934265137\n",
      "epoch 0, batch 200, loss = 2.9349331855773926\n",
      "epoch 0, batch 210, loss = 2.9363608360290527\n",
      "epoch 0, batch 220, loss = 2.9940857887268066\n",
      "epoch 0, batch 230, loss = 2.948225498199463\n",
      "epoch 0, batch 240, loss = 2.969679355621338\n",
      "epoch 0, batch 250, loss = 2.9601640701293945\n",
      "epoch 0, batch 260, loss = 2.952479600906372\n",
      "epoch 0, batch 270, loss = 2.917694568634033\n",
      "epoch 0, batch 280, loss = 2.9067447185516357\n",
      "epoch 1, batch 0, loss = 2.9064645767211914\n",
      "epoch 1, batch 10, loss = 2.9435253143310547\n",
      "epoch 1, batch 20, loss = 2.938819408416748\n",
      "epoch 1, batch 30, loss = 2.8832149505615234\n",
      "epoch 1, batch 40, loss = 2.914644956588745\n",
      "epoch 1, batch 50, loss = 2.880033254623413\n",
      "epoch 1, batch 60, loss = 2.902492046356201\n",
      "epoch 1, batch 70, loss = 2.9157419204711914\n",
      "epoch 1, batch 80, loss = 2.927762985229492\n",
      "epoch 1, batch 90, loss = 2.850933790206909\n",
      "epoch 1, batch 100, loss = 2.9032115936279297\n",
      "epoch 1, batch 110, loss = 2.856438636779785\n",
      "epoch 1, batch 120, loss = 2.874415397644043\n",
      "epoch 1, batch 130, loss = 2.8638877868652344\n",
      "epoch 1, batch 140, loss = 2.860034942626953\n",
      "epoch 1, batch 150, loss = 2.8496904373168945\n",
      "epoch 1, batch 160, loss = 2.8609488010406494\n",
      "epoch 1, batch 170, loss = 2.8609237670898438\n",
      "epoch 1, batch 180, loss = 2.8743371963500977\n",
      "epoch 1, batch 190, loss = 2.880889415740967\n",
      "epoch 1, batch 200, loss = 2.9212963581085205\n",
      "epoch 1, batch 210, loss = 2.8399691581726074\n",
      "epoch 1, batch 220, loss = 2.9180960655212402\n",
      "epoch 1, batch 230, loss = 2.846682548522949\n",
      "epoch 1, batch 240, loss = 2.8577609062194824\n",
      "epoch 1, batch 250, loss = 2.889840602874756\n",
      "epoch 1, batch 260, loss = 2.8843283653259277\n",
      "epoch 1, batch 270, loss = 2.8747286796569824\n",
      "epoch 1, batch 280, loss = 2.858491897583008\n",
      "epoch 2, batch 0, loss = 2.912323474884033\n",
      "epoch 2, batch 10, loss = 2.787926197052002\n",
      "epoch 2, batch 20, loss = 2.8581671714782715\n",
      "epoch 2, batch 30, loss = 2.87038254737854\n",
      "epoch 2, batch 40, loss = 2.8762364387512207\n",
      "epoch 2, batch 50, loss = 2.8562448024749756\n",
      "epoch 2, batch 60, loss = 2.8446707725524902\n",
      "epoch 2, batch 70, loss = 2.861257314682007\n",
      "epoch 2, batch 80, loss = 2.8623905181884766\n",
      "epoch 2, batch 90, loss = 2.80692720413208\n",
      "epoch 2, batch 100, loss = 2.8415794372558594\n",
      "epoch 2, batch 110, loss = 2.8694653511047363\n",
      "epoch 2, batch 120, loss = 2.8158812522888184\n",
      "epoch 2, batch 130, loss = 2.850733518600464\n",
      "epoch 2, batch 140, loss = 2.820730209350586\n",
      "epoch 2, batch 150, loss = 2.8211495876312256\n",
      "epoch 2, batch 160, loss = 2.8693885803222656\n",
      "epoch 2, batch 170, loss = 2.805346965789795\n",
      "epoch 2, batch 180, loss = 2.798107147216797\n",
      "epoch 2, batch 190, loss = 2.8226747512817383\n",
      "epoch 2, batch 200, loss = 2.819776773452759\n",
      "epoch 2, batch 210, loss = 2.799027919769287\n",
      "epoch 2, batch 220, loss = 2.855290412902832\n",
      "epoch 2, batch 230, loss = 2.853675365447998\n",
      "epoch 2, batch 240, loss = 2.873767375946045\n",
      "epoch 2, batch 250, loss = 2.8433892726898193\n",
      "epoch 2, batch 260, loss = 2.8609814643859863\n",
      "epoch 2, batch 270, loss = 2.8175928592681885\n",
      "epoch 2, batch 280, loss = 2.851956367492676\n",
      "epoch 3, batch 0, loss = 2.8052074909210205\n",
      "epoch 3, batch 10, loss = 2.83967924118042\n",
      "epoch 3, batch 20, loss = 2.8506178855895996\n",
      "epoch 3, batch 30, loss = 2.8432295322418213\n",
      "epoch 3, batch 40, loss = 2.8087713718414307\n",
      "epoch 3, batch 50, loss = 2.8553926944732666\n",
      "epoch 3, batch 60, loss = 2.8094534873962402\n",
      "epoch 3, batch 70, loss = 2.8155646324157715\n",
      "epoch 3, batch 80, loss = 2.8437161445617676\n",
      "epoch 3, batch 90, loss = 2.868896961212158\n",
      "epoch 3, batch 100, loss = 2.7568674087524414\n",
      "epoch 3, batch 110, loss = 2.9076592922210693\n",
      "epoch 3, batch 120, loss = 2.83298397064209\n",
      "epoch 3, batch 130, loss = 2.8196380138397217\n",
      "epoch 3, batch 140, loss = 2.8635244369506836\n",
      "epoch 3, batch 150, loss = 2.8277201652526855\n",
      "epoch 3, batch 160, loss = 2.8439440727233887\n",
      "epoch 3, batch 170, loss = 2.803417205810547\n",
      "epoch 3, batch 180, loss = 2.798478126525879\n",
      "epoch 3, batch 190, loss = 2.7964015007019043\n",
      "epoch 3, batch 200, loss = 2.778536796569824\n",
      "epoch 3, batch 210, loss = 2.852181911468506\n",
      "epoch 3, batch 220, loss = 2.855217933654785\n",
      "epoch 3, batch 230, loss = 2.8306195735931396\n",
      "epoch 3, batch 240, loss = 2.817728042602539\n",
      "epoch 3, batch 250, loss = 2.8399410247802734\n",
      "epoch 3, batch 260, loss = 2.822160243988037\n",
      "epoch 3, batch 270, loss = 2.856154441833496\n",
      "epoch 3, batch 280, loss = 2.832719326019287\n",
      "epoch 4, batch 0, loss = 2.7968764305114746\n",
      "epoch 4, batch 10, loss = 2.7557730674743652\n",
      "epoch 4, batch 20, loss = 2.8231005668640137\n",
      "epoch 4, batch 30, loss = 2.8676509857177734\n",
      "epoch 4, batch 40, loss = 2.8376059532165527\n",
      "epoch 4, batch 50, loss = 2.7901759147644043\n",
      "epoch 4, batch 60, loss = 2.7864584922790527\n",
      "epoch 4, batch 70, loss = 2.8325579166412354\n",
      "epoch 4, batch 80, loss = 2.7981038093566895\n",
      "epoch 4, batch 90, loss = 2.7800920009613037\n",
      "epoch 4, batch 100, loss = 2.782874584197998\n",
      "epoch 4, batch 110, loss = 2.849187135696411\n",
      "epoch 4, batch 120, loss = 2.8012595176696777\n",
      "epoch 4, batch 130, loss = 2.8127763271331787\n",
      "epoch 4, batch 140, loss = 2.7999472618103027\n",
      "epoch 4, batch 150, loss = 2.8215742111206055\n",
      "epoch 4, batch 160, loss = 2.869565486907959\n",
      "epoch 4, batch 170, loss = 2.7943387031555176\n",
      "epoch 4, batch 180, loss = 2.815558671951294\n",
      "epoch 4, batch 190, loss = 2.782435894012451\n",
      "epoch 4, batch 200, loss = 2.7898457050323486\n",
      "epoch 4, batch 210, loss = 2.7961249351501465\n",
      "epoch 4, batch 220, loss = 2.839858055114746\n",
      "epoch 4, batch 230, loss = 2.7942960262298584\n",
      "epoch 4, batch 240, loss = 2.7843430042266846\n",
      "epoch 4, batch 250, loss = 2.8007965087890625\n",
      "epoch 4, batch 260, loss = 2.810866117477417\n",
      "epoch 4, batch 270, loss = 2.787412643432617\n",
      "epoch 4, batch 280, loss = 2.798628330230713\n",
      "epoch 5, batch 0, loss = 2.8500447273254395\n",
      "epoch 5, batch 10, loss = 2.7775864601135254\n",
      "epoch 5, batch 20, loss = 2.778785228729248\n",
      "epoch 5, batch 30, loss = 2.7909469604492188\n",
      "epoch 5, batch 40, loss = 2.792109489440918\n",
      "epoch 5, batch 50, loss = 2.773728847503662\n",
      "epoch 5, batch 60, loss = 2.7927231788635254\n",
      "epoch 5, batch 70, loss = 2.832366466522217\n",
      "epoch 5, batch 80, loss = 2.7462077140808105\n",
      "epoch 5, batch 90, loss = 2.7720160484313965\n",
      "epoch 5, batch 100, loss = 2.767542600631714\n",
      "epoch 5, batch 110, loss = 2.7818779945373535\n",
      "epoch 5, batch 120, loss = 2.7572875022888184\n",
      "epoch 5, batch 130, loss = 2.774559259414673\n",
      "epoch 5, batch 140, loss = 2.809877872467041\n",
      "epoch 5, batch 150, loss = 2.798786163330078\n",
      "epoch 5, batch 160, loss = 2.852263927459717\n",
      "epoch 5, batch 170, loss = 2.7505922317504883\n",
      "epoch 5, batch 180, loss = 2.7869138717651367\n",
      "epoch 5, batch 190, loss = 2.814788818359375\n",
      "epoch 5, batch 200, loss = 2.835721969604492\n",
      "epoch 5, batch 210, loss = 2.7404637336730957\n",
      "epoch 5, batch 220, loss = 2.7712838649749756\n",
      "epoch 5, batch 230, loss = 2.8167734146118164\n",
      "epoch 5, batch 240, loss = 2.8191046714782715\n",
      "epoch 5, batch 250, loss = 2.7795581817626953\n",
      "epoch 5, batch 260, loss = 2.7892184257507324\n",
      "epoch 5, batch 270, loss = 2.8529202938079834\n",
      "epoch 5, batch 280, loss = 2.816648006439209\n",
      "epoch 6, batch 0, loss = 2.8199193477630615\n",
      "epoch 6, batch 10, loss = 2.8004581928253174\n",
      "epoch 6, batch 20, loss = 2.7685322761535645\n",
      "epoch 6, batch 30, loss = 2.8010973930358887\n",
      "epoch 6, batch 40, loss = 2.7909960746765137\n",
      "epoch 6, batch 50, loss = 2.753056287765503\n",
      "epoch 6, batch 60, loss = 2.7825231552124023\n",
      "epoch 6, batch 70, loss = 2.764896869659424\n",
      "epoch 6, batch 80, loss = 2.7375693321228027\n",
      "epoch 6, batch 90, loss = 2.808680534362793\n",
      "epoch 6, batch 100, loss = 2.790346384048462\n",
      "epoch 6, batch 110, loss = 2.721508264541626\n",
      "epoch 6, batch 120, loss = 2.800309896469116\n",
      "epoch 6, batch 130, loss = 2.8016281127929688\n",
      "epoch 6, batch 140, loss = 2.7833428382873535\n",
      "epoch 6, batch 150, loss = 2.8190736770629883\n",
      "epoch 6, batch 160, loss = 2.813612937927246\n",
      "epoch 6, batch 170, loss = 2.837704658508301\n",
      "epoch 6, batch 180, loss = 2.7571380138397217\n",
      "epoch 6, batch 190, loss = 2.7676050662994385\n",
      "epoch 6, batch 200, loss = 2.8133745193481445\n",
      "epoch 6, batch 210, loss = 2.8720667362213135\n",
      "epoch 6, batch 220, loss = 2.786289930343628\n",
      "epoch 6, batch 230, loss = 2.8151133060455322\n",
      "epoch 6, batch 240, loss = 2.757779598236084\n",
      "epoch 6, batch 250, loss = 2.775268077850342\n",
      "epoch 6, batch 260, loss = 2.80588436126709\n",
      "epoch 6, batch 270, loss = 2.7912182807922363\n",
      "epoch 6, batch 280, loss = 2.7720162868499756\n",
      "epoch 7, batch 0, loss = 2.8004932403564453\n",
      "epoch 7, batch 10, loss = 2.7658843994140625\n",
      "epoch 7, batch 20, loss = 2.744661808013916\n",
      "epoch 7, batch 30, loss = 2.751908302307129\n",
      "epoch 7, batch 40, loss = 2.7815520763397217\n",
      "epoch 7, batch 50, loss = 2.738025188446045\n",
      "epoch 7, batch 60, loss = 2.753936767578125\n",
      "epoch 7, batch 70, loss = 2.7326793670654297\n",
      "epoch 7, batch 80, loss = 2.8243494033813477\n",
      "epoch 7, batch 90, loss = 2.758314609527588\n",
      "epoch 7, batch 100, loss = 2.783515453338623\n",
      "epoch 7, batch 110, loss = 2.788168430328369\n",
      "epoch 7, batch 120, loss = 2.8046326637268066\n",
      "epoch 7, batch 130, loss = 2.7979226112365723\n",
      "epoch 7, batch 140, loss = 2.7486324310302734\n",
      "epoch 7, batch 150, loss = 2.7956957817077637\n",
      "epoch 7, batch 160, loss = 2.8043854236602783\n",
      "epoch 7, batch 170, loss = 2.745382785797119\n",
      "epoch 7, batch 180, loss = 2.7667226791381836\n",
      "epoch 7, batch 190, loss = 2.7632224559783936\n",
      "epoch 7, batch 200, loss = 2.764744281768799\n",
      "epoch 7, batch 210, loss = 2.825028419494629\n",
      "epoch 7, batch 220, loss = 2.7560572624206543\n",
      "epoch 7, batch 230, loss = 2.8480772972106934\n",
      "epoch 7, batch 240, loss = 2.799840211868286\n",
      "epoch 7, batch 250, loss = 2.7411797046661377\n",
      "epoch 7, batch 260, loss = 2.746321678161621\n",
      "epoch 7, batch 270, loss = 2.786581516265869\n",
      "epoch 7, batch 280, loss = 2.8202123641967773\n",
      "epoch 8, batch 0, loss = 2.8285293579101562\n",
      "epoch 8, batch 10, loss = 2.772768020629883\n",
      "epoch 8, batch 20, loss = 2.797257423400879\n",
      "epoch 8, batch 30, loss = 2.7627196311950684\n",
      "epoch 8, batch 40, loss = 2.76973295211792\n",
      "epoch 8, batch 50, loss = 2.7373313903808594\n",
      "epoch 8, batch 60, loss = 2.8044426441192627\n",
      "epoch 8, batch 70, loss = 2.749783515930176\n",
      "epoch 8, batch 80, loss = 2.7314822673797607\n",
      "epoch 8, batch 90, loss = 2.763479709625244\n",
      "epoch 8, batch 100, loss = 2.76310396194458\n",
      "epoch 8, batch 110, loss = 2.7631564140319824\n",
      "epoch 8, batch 120, loss = 2.760331869125366\n",
      "epoch 8, batch 130, loss = 2.749856472015381\n",
      "epoch 8, batch 140, loss = 2.813643455505371\n",
      "epoch 8, batch 150, loss = 2.791287422180176\n",
      "epoch 8, batch 160, loss = 2.827293872833252\n",
      "epoch 8, batch 170, loss = 2.8094120025634766\n",
      "epoch 8, batch 180, loss = 2.769529342651367\n",
      "epoch 8, batch 190, loss = 2.774728298187256\n",
      "epoch 8, batch 200, loss = 2.783949375152588\n",
      "epoch 8, batch 210, loss = 2.7597811222076416\n",
      "epoch 8, batch 220, loss = 2.8123738765716553\n",
      "epoch 8, batch 230, loss = 2.727415084838867\n",
      "epoch 8, batch 240, loss = 2.7820916175842285\n",
      "epoch 8, batch 250, loss = 2.7916650772094727\n",
      "epoch 8, batch 260, loss = 2.768214225769043\n",
      "epoch 8, batch 270, loss = 2.70717716217041\n",
      "epoch 8, batch 280, loss = 2.7896463871002197\n",
      "epoch 9, batch 0, loss = 2.810614824295044\n",
      "epoch 9, batch 10, loss = 2.756826877593994\n",
      "epoch 9, batch 20, loss = 2.7319087982177734\n",
      "epoch 9, batch 30, loss = 2.737809181213379\n",
      "epoch 9, batch 40, loss = 2.7842822074890137\n",
      "epoch 9, batch 50, loss = 2.783905029296875\n",
      "epoch 9, batch 60, loss = 2.7269370555877686\n",
      "epoch 9, batch 70, loss = 2.7156150341033936\n",
      "epoch 9, batch 80, loss = 2.719754457473755\n",
      "epoch 9, batch 90, loss = 2.7998952865600586\n",
      "epoch 9, batch 100, loss = 2.7706832885742188\n",
      "epoch 9, batch 110, loss = 2.754279613494873\n",
      "epoch 9, batch 120, loss = 2.7302863597869873\n",
      "epoch 9, batch 130, loss = 2.7700958251953125\n",
      "epoch 9, batch 140, loss = 2.7272605895996094\n",
      "epoch 9, batch 150, loss = 2.835630416870117\n",
      "epoch 9, batch 160, loss = 2.771275520324707\n",
      "epoch 9, batch 170, loss = 2.7487096786499023\n",
      "epoch 9, batch 180, loss = 2.7308945655822754\n",
      "epoch 9, batch 190, loss = 2.7635931968688965\n",
      "epoch 9, batch 200, loss = 2.7828354835510254\n",
      "epoch 9, batch 210, loss = 2.792470693588257\n",
      "epoch 9, batch 220, loss = 2.7909841537475586\n",
      "epoch 9, batch 230, loss = 2.8119096755981445\n",
      "epoch 9, batch 240, loss = 2.6855218410491943\n",
      "epoch 9, batch 250, loss = 2.762599468231201\n",
      "epoch 9, batch 260, loss = 2.7932090759277344\n",
      "epoch 9, batch 270, loss = 2.761916160583496\n",
      "epoch 9, batch 280, loss = 2.769718647003174\n",
      "epoch 10, batch 0, loss = 2.7748680114746094\n",
      "epoch 10, batch 10, loss = 2.734513998031616\n",
      "epoch 10, batch 20, loss = 2.728757858276367\n",
      "epoch 10, batch 30, loss = 2.7352147102355957\n",
      "epoch 10, batch 40, loss = 2.711956024169922\n",
      "epoch 10, batch 50, loss = 2.7012009620666504\n",
      "epoch 10, batch 60, loss = 2.7368712425231934\n",
      "epoch 10, batch 70, loss = 2.720000982284546\n",
      "epoch 10, batch 80, loss = 2.6936728954315186\n",
      "epoch 10, batch 90, loss = 2.795560359954834\n",
      "epoch 10, batch 100, loss = 2.7944822311401367\n",
      "epoch 10, batch 110, loss = 2.7317512035369873\n",
      "epoch 10, batch 120, loss = 2.8005638122558594\n",
      "epoch 10, batch 130, loss = 2.7655506134033203\n",
      "epoch 10, batch 140, loss = 2.747227430343628\n",
      "epoch 10, batch 150, loss = 2.770930290222168\n",
      "epoch 10, batch 160, loss = 2.759014368057251\n",
      "epoch 10, batch 170, loss = 2.799022674560547\n",
      "epoch 10, batch 180, loss = 2.74015474319458\n",
      "epoch 10, batch 190, loss = 2.742663860321045\n",
      "epoch 10, batch 200, loss = 2.7616703510284424\n",
      "epoch 10, batch 210, loss = 2.769803047180176\n",
      "epoch 10, batch 220, loss = 2.738306999206543\n",
      "epoch 10, batch 230, loss = 2.7433395385742188\n",
      "epoch 10, batch 240, loss = 2.7909064292907715\n",
      "epoch 10, batch 250, loss = 2.7773494720458984\n",
      "epoch 10, batch 260, loss = 2.764458179473877\n",
      "epoch 10, batch 270, loss = 2.7412056922912598\n",
      "epoch 10, batch 280, loss = 2.7981932163238525\n",
      "epoch 11, batch 0, loss = 2.736051559448242\n",
      "epoch 11, batch 10, loss = 2.720823287963867\n",
      "epoch 11, batch 20, loss = 2.8067102432250977\n",
      "epoch 11, batch 30, loss = 2.7659943103790283\n",
      "epoch 11, batch 40, loss = 2.799278974533081\n",
      "epoch 11, batch 50, loss = 2.7244229316711426\n",
      "epoch 11, batch 60, loss = 2.713710308074951\n",
      "epoch 11, batch 70, loss = 2.746405839920044\n",
      "epoch 11, batch 80, loss = 2.8000450134277344\n",
      "epoch 11, batch 90, loss = 2.767935276031494\n",
      "epoch 11, batch 100, loss = 2.716728448867798\n",
      "epoch 11, batch 110, loss = 2.765730381011963\n",
      "epoch 11, batch 120, loss = 2.750396251678467\n",
      "epoch 11, batch 130, loss = 2.7554092407226562\n",
      "epoch 11, batch 140, loss = 2.7715702056884766\n",
      "epoch 11, batch 150, loss = 2.751659393310547\n",
      "epoch 11, batch 160, loss = 2.7408225536346436\n",
      "epoch 11, batch 170, loss = 2.6788182258605957\n",
      "epoch 11, batch 180, loss = 2.748619318008423\n",
      "epoch 11, batch 190, loss = 2.685148239135742\n",
      "epoch 11, batch 200, loss = 2.7006514072418213\n",
      "epoch 11, batch 210, loss = 2.758772373199463\n",
      "epoch 11, batch 220, loss = 2.7820582389831543\n",
      "epoch 11, batch 230, loss = 2.7328696250915527\n",
      "epoch 11, batch 240, loss = 2.77244234085083\n",
      "epoch 11, batch 250, loss = 2.721158027648926\n",
      "epoch 11, batch 260, loss = 2.752458095550537\n",
      "epoch 11, batch 270, loss = 2.6968061923980713\n",
      "epoch 11, batch 280, loss = 2.7334794998168945\n",
      "epoch 12, batch 0, loss = 2.723175525665283\n",
      "epoch 12, batch 10, loss = 2.70239520072937\n",
      "epoch 12, batch 20, loss = 2.7273025512695312\n",
      "epoch 12, batch 30, loss = 2.7462563514709473\n",
      "epoch 12, batch 40, loss = 2.739506483078003\n",
      "epoch 12, batch 50, loss = 2.7701289653778076\n",
      "epoch 12, batch 60, loss = 2.7244112491607666\n",
      "epoch 12, batch 70, loss = 2.7831649780273438\n",
      "epoch 12, batch 80, loss = 2.7797882556915283\n",
      "epoch 12, batch 90, loss = 2.75357723236084\n",
      "epoch 12, batch 100, loss = 2.7072510719299316\n",
      "epoch 12, batch 110, loss = 2.740774631500244\n",
      "epoch 12, batch 120, loss = 2.7206692695617676\n",
      "epoch 12, batch 130, loss = 2.768411159515381\n",
      "epoch 12, batch 140, loss = 2.792900323867798\n",
      "epoch 12, batch 150, loss = 2.768730878829956\n",
      "epoch 12, batch 160, loss = 2.752863645553589\n",
      "epoch 12, batch 170, loss = 2.7875022888183594\n",
      "epoch 12, batch 180, loss = 2.730508804321289\n",
      "epoch 12, batch 190, loss = 2.7793211936950684\n",
      "epoch 12, batch 200, loss = 2.7603652477264404\n",
      "epoch 12, batch 210, loss = 2.746650218963623\n",
      "epoch 12, batch 220, loss = 2.742964744567871\n",
      "epoch 12, batch 230, loss = 2.771318197250366\n",
      "epoch 12, batch 240, loss = 2.696256637573242\n",
      "epoch 12, batch 250, loss = 2.7234067916870117\n",
      "epoch 12, batch 260, loss = 2.7491068840026855\n",
      "epoch 12, batch 270, loss = 2.7442803382873535\n",
      "epoch 12, batch 280, loss = 2.7650835514068604\n",
      "epoch 13, batch 0, loss = 2.7289364337921143\n",
      "epoch 13, batch 10, loss = 2.6722748279571533\n",
      "epoch 13, batch 20, loss = 2.723689556121826\n",
      "epoch 13, batch 30, loss = 2.744534969329834\n",
      "epoch 13, batch 40, loss = 2.7303287982940674\n",
      "epoch 13, batch 50, loss = 2.727754831314087\n",
      "epoch 13, batch 60, loss = 2.732506275177002\n",
      "epoch 13, batch 70, loss = 2.7120680809020996\n",
      "epoch 13, batch 80, loss = 2.750159502029419\n",
      "epoch 13, batch 90, loss = 2.7019612789154053\n",
      "epoch 13, batch 100, loss = 2.726395606994629\n",
      "epoch 13, batch 110, loss = 2.7460482120513916\n",
      "epoch 13, batch 120, loss = 2.7313613891601562\n",
      "epoch 13, batch 130, loss = 2.780447006225586\n",
      "epoch 13, batch 140, loss = 2.7949514389038086\n",
      "epoch 13, batch 150, loss = 2.772092819213867\n",
      "epoch 13, batch 160, loss = 2.729050636291504\n",
      "epoch 13, batch 170, loss = 2.777499198913574\n",
      "epoch 13, batch 180, loss = 2.732572078704834\n",
      "epoch 13, batch 190, loss = 2.7473697662353516\n",
      "epoch 13, batch 200, loss = 2.750528335571289\n",
      "epoch 13, batch 210, loss = 2.7270257472991943\n",
      "epoch 13, batch 220, loss = 2.732151985168457\n",
      "epoch 13, batch 230, loss = 2.732865571975708\n",
      "epoch 13, batch 240, loss = 2.74857234954834\n",
      "epoch 13, batch 250, loss = 2.74481201171875\n",
      "epoch 13, batch 260, loss = 2.733154296875\n",
      "epoch 13, batch 270, loss = 2.7700634002685547\n",
      "epoch 13, batch 280, loss = 2.8159689903259277\n",
      "epoch 14, batch 0, loss = 2.723163604736328\n",
      "epoch 14, batch 10, loss = 2.707977771759033\n",
      "epoch 14, batch 20, loss = 2.7979931831359863\n",
      "epoch 14, batch 30, loss = 2.736231565475464\n",
      "epoch 14, batch 40, loss = 2.7319066524505615\n",
      "epoch 14, batch 50, loss = 2.757046699523926\n",
      "epoch 14, batch 60, loss = 2.7619476318359375\n",
      "epoch 14, batch 70, loss = 2.738359212875366\n",
      "epoch 14, batch 80, loss = 2.744497776031494\n",
      "epoch 14, batch 90, loss = 2.7097668647766113\n",
      "epoch 14, batch 100, loss = 2.7708897590637207\n",
      "epoch 14, batch 110, loss = 2.7614736557006836\n",
      "epoch 14, batch 120, loss = 2.740084648132324\n",
      "epoch 14, batch 130, loss = 2.7264342308044434\n",
      "epoch 14, batch 140, loss = 2.7447822093963623\n",
      "epoch 14, batch 150, loss = 2.694122791290283\n",
      "epoch 14, batch 160, loss = 2.6767055988311768\n",
      "epoch 14, batch 170, loss = 2.760863780975342\n",
      "epoch 14, batch 180, loss = 2.7708120346069336\n",
      "epoch 14, batch 190, loss = 2.7350306510925293\n",
      "epoch 14, batch 200, loss = 2.7410855293273926\n",
      "epoch 14, batch 210, loss = 2.7668352127075195\n",
      "epoch 14, batch 220, loss = 2.719477653503418\n",
      "epoch 14, batch 230, loss = 2.7412760257720947\n",
      "epoch 14, batch 240, loss = 2.736168622970581\n",
      "epoch 14, batch 250, loss = 2.726738452911377\n",
      "epoch 14, batch 260, loss = 2.7259035110473633\n",
      "epoch 14, batch 270, loss = 2.7990355491638184\n",
      "epoch 14, batch 280, loss = 2.742396354675293\n",
      "epoch 15, batch 0, loss = 2.737421751022339\n",
      "epoch 15, batch 10, loss = 2.724738359451294\n",
      "epoch 15, batch 20, loss = 2.759526491165161\n",
      "epoch 15, batch 30, loss = 2.755019187927246\n",
      "epoch 15, batch 40, loss = 2.687582015991211\n",
      "epoch 15, batch 50, loss = 2.7315311431884766\n",
      "epoch 15, batch 60, loss = 2.687045097351074\n",
      "epoch 15, batch 70, loss = 2.746119976043701\n",
      "epoch 15, batch 80, loss = 2.774113178253174\n",
      "epoch 15, batch 90, loss = 2.7311549186706543\n",
      "epoch 15, batch 100, loss = 2.723419666290283\n",
      "epoch 15, batch 110, loss = 2.6780245304107666\n",
      "epoch 15, batch 120, loss = 2.8019752502441406\n",
      "epoch 15, batch 130, loss = 2.7057294845581055\n",
      "epoch 15, batch 140, loss = 2.7381410598754883\n",
      "epoch 15, batch 150, loss = 2.6859312057495117\n",
      "epoch 15, batch 160, loss = 2.7016289234161377\n",
      "epoch 15, batch 170, loss = 2.7569735050201416\n",
      "epoch 15, batch 180, loss = 2.74517822265625\n",
      "epoch 15, batch 190, loss = 2.678846597671509\n",
      "epoch 15, batch 200, loss = 2.7743983268737793\n",
      "epoch 15, batch 210, loss = 2.7608580589294434\n",
      "epoch 15, batch 220, loss = 2.805762767791748\n",
      "epoch 15, batch 230, loss = 2.751667022705078\n",
      "epoch 15, batch 240, loss = 2.7383275032043457\n",
      "epoch 15, batch 250, loss = 2.6852989196777344\n",
      "epoch 15, batch 260, loss = 2.7157015800476074\n",
      "epoch 15, batch 270, loss = 2.7640562057495117\n",
      "epoch 15, batch 280, loss = 2.773754596710205\n",
      "epoch 16, batch 0, loss = 2.7048749923706055\n",
      "epoch 16, batch 10, loss = 2.697451591491699\n",
      "epoch 16, batch 20, loss = 2.6967201232910156\n",
      "epoch 16, batch 30, loss = 2.7500193119049072\n",
      "epoch 16, batch 40, loss = 2.7227942943573\n",
      "epoch 16, batch 50, loss = 2.7138750553131104\n",
      "epoch 16, batch 60, loss = 2.7797861099243164\n",
      "epoch 16, batch 70, loss = 2.7784576416015625\n",
      "epoch 16, batch 80, loss = 2.720634698867798\n",
      "epoch 16, batch 90, loss = 2.738247871398926\n",
      "epoch 16, batch 100, loss = 2.739919900894165\n",
      "epoch 16, batch 110, loss = 2.746417999267578\n",
      "epoch 16, batch 120, loss = 2.784891366958618\n",
      "epoch 16, batch 130, loss = 2.739065170288086\n",
      "epoch 16, batch 140, loss = 2.7560412883758545\n",
      "epoch 16, batch 150, loss = 2.7308225631713867\n",
      "epoch 16, batch 160, loss = 2.7110867500305176\n",
      "epoch 16, batch 170, loss = 2.8130393028259277\n",
      "epoch 16, batch 180, loss = 2.737064838409424\n",
      "epoch 16, batch 190, loss = 2.716036796569824\n",
      "epoch 16, batch 200, loss = 2.740621328353882\n",
      "epoch 16, batch 210, loss = 2.7288501262664795\n",
      "epoch 16, batch 220, loss = 2.727564811706543\n",
      "epoch 16, batch 230, loss = 2.7695693969726562\n",
      "epoch 16, batch 240, loss = 2.749427318572998\n",
      "epoch 16, batch 250, loss = 2.7110743522644043\n",
      "epoch 16, batch 260, loss = 2.742766857147217\n",
      "epoch 16, batch 270, loss = 2.696793556213379\n",
      "epoch 16, batch 280, loss = 2.7068958282470703\n",
      "epoch 17, batch 0, loss = 2.7077574729919434\n",
      "epoch 17, batch 10, loss = 2.732635974884033\n",
      "epoch 17, batch 20, loss = 2.6892032623291016\n",
      "epoch 17, batch 30, loss = 2.775330066680908\n",
      "epoch 17, batch 40, loss = 2.6986188888549805\n",
      "epoch 17, batch 50, loss = 2.7119979858398438\n",
      "epoch 17, batch 60, loss = 2.695988655090332\n",
      "epoch 17, batch 70, loss = 2.6901628971099854\n",
      "epoch 17, batch 80, loss = 2.7686386108398438\n",
      "epoch 17, batch 90, loss = 2.739431858062744\n",
      "epoch 17, batch 100, loss = 2.6769003868103027\n",
      "epoch 17, batch 110, loss = 2.785353183746338\n",
      "epoch 17, batch 120, loss = 2.7117247581481934\n",
      "epoch 17, batch 130, loss = 2.7815041542053223\n",
      "epoch 17, batch 140, loss = 2.715956211090088\n",
      "epoch 17, batch 150, loss = 2.6674580574035645\n",
      "epoch 17, batch 160, loss = 2.7650182247161865\n",
      "epoch 17, batch 170, loss = 2.7519097328186035\n",
      "epoch 17, batch 180, loss = 2.6822147369384766\n",
      "epoch 17, batch 190, loss = 2.725552797317505\n",
      "epoch 17, batch 200, loss = 2.7085061073303223\n",
      "epoch 17, batch 210, loss = 2.7504727840423584\n",
      "epoch 17, batch 220, loss = 2.726489543914795\n",
      "epoch 17, batch 230, loss = 2.6899867057800293\n",
      "epoch 17, batch 240, loss = 2.6850247383117676\n",
      "epoch 17, batch 250, loss = 2.732722282409668\n",
      "epoch 17, batch 260, loss = 2.7483296394348145\n",
      "epoch 17, batch 270, loss = 2.7947776317596436\n",
      "epoch 17, batch 280, loss = 2.7164413928985596\n",
      "epoch 18, batch 0, loss = 2.709160327911377\n",
      "epoch 18, batch 10, loss = 2.7767062187194824\n",
      "epoch 18, batch 20, loss = 2.7640042304992676\n",
      "epoch 18, batch 30, loss = 2.756284236907959\n",
      "epoch 18, batch 40, loss = 2.7034950256347656\n",
      "epoch 18, batch 50, loss = 2.7019619941711426\n",
      "epoch 18, batch 60, loss = 2.759798049926758\n",
      "epoch 18, batch 70, loss = 2.7405288219451904\n",
      "epoch 18, batch 80, loss = 2.6923723220825195\n",
      "epoch 18, batch 90, loss = 2.705756664276123\n",
      "epoch 18, batch 100, loss = 2.78743577003479\n",
      "epoch 18, batch 110, loss = 2.670084238052368\n",
      "epoch 18, batch 120, loss = 2.7573766708374023\n",
      "epoch 18, batch 130, loss = 2.6962172985076904\n",
      "epoch 18, batch 140, loss = 2.741486072540283\n",
      "epoch 18, batch 150, loss = 2.7703089714050293\n",
      "epoch 18, batch 160, loss = 2.6914520263671875\n",
      "epoch 18, batch 170, loss = 2.6967954635620117\n",
      "epoch 18, batch 180, loss = 2.744321823120117\n",
      "epoch 18, batch 190, loss = 2.720409870147705\n",
      "epoch 18, batch 200, loss = 2.750882148742676\n",
      "epoch 18, batch 210, loss = 2.7246804237365723\n",
      "epoch 18, batch 220, loss = 2.7250070571899414\n",
      "epoch 18, batch 230, loss = 2.7839927673339844\n",
      "epoch 18, batch 240, loss = 2.7890026569366455\n",
      "epoch 18, batch 250, loss = 2.7191619873046875\n",
      "epoch 18, batch 260, loss = 2.7209575176239014\n",
      "epoch 18, batch 270, loss = 2.730809450149536\n",
      "epoch 18, batch 280, loss = 2.704106569290161\n",
      "epoch 19, batch 0, loss = 2.7645883560180664\n",
      "epoch 19, batch 10, loss = 2.6893086433410645\n",
      "epoch 19, batch 20, loss = 2.685882568359375\n",
      "epoch 19, batch 30, loss = 2.70644211769104\n",
      "epoch 19, batch 40, loss = 2.7108850479125977\n",
      "epoch 19, batch 50, loss = 2.6879634857177734\n",
      "epoch 19, batch 60, loss = 2.7299699783325195\n",
      "epoch 19, batch 70, loss = 2.736086845397949\n",
      "epoch 19, batch 80, loss = 2.699524402618408\n",
      "epoch 19, batch 90, loss = 2.7467939853668213\n",
      "epoch 19, batch 100, loss = 2.693389892578125\n",
      "epoch 19, batch 110, loss = 2.7321858406066895\n",
      "epoch 19, batch 120, loss = 2.700558662414551\n",
      "epoch 19, batch 130, loss = 2.6938118934631348\n",
      "epoch 19, batch 140, loss = 2.6729328632354736\n",
      "epoch 19, batch 150, loss = 2.721398115158081\n",
      "epoch 19, batch 160, loss = 2.7047767639160156\n",
      "epoch 19, batch 170, loss = 2.7265233993530273\n",
      "epoch 19, batch 180, loss = 2.6783008575439453\n",
      "epoch 19, batch 190, loss = 2.708890676498413\n",
      "epoch 19, batch 200, loss = 2.7835965156555176\n",
      "epoch 19, batch 210, loss = 2.7014713287353516\n",
      "epoch 19, batch 220, loss = 2.746795654296875\n",
      "epoch 19, batch 230, loss = 2.690399646759033\n",
      "epoch 19, batch 240, loss = 2.748547315597534\n",
      "epoch 19, batch 250, loss = 2.6666603088378906\n",
      "epoch 19, batch 260, loss = 2.7284939289093018\n",
      "epoch 19, batch 270, loss = 2.7234978675842285\n",
      "epoch 19, batch 280, loss = 2.651827573776245\n",
      "epoch 20, batch 0, loss = 2.7732350826263428\n",
      "epoch 20, batch 10, loss = 2.7082760334014893\n",
      "epoch 20, batch 20, loss = 2.6768569946289062\n",
      "epoch 20, batch 30, loss = 2.7103967666625977\n",
      "epoch 20, batch 40, loss = 2.6936464309692383\n",
      "epoch 20, batch 50, loss = 2.7165944576263428\n",
      "epoch 20, batch 60, loss = 2.6799192428588867\n",
      "epoch 20, batch 70, loss = 2.681910991668701\n",
      "epoch 20, batch 80, loss = 2.715895652770996\n",
      "epoch 20, batch 90, loss = 2.741528272628784\n",
      "epoch 20, batch 100, loss = 2.7340025901794434\n",
      "epoch 20, batch 110, loss = 2.781529426574707\n",
      "epoch 20, batch 120, loss = 2.7267532348632812\n",
      "epoch 20, batch 130, loss = 2.7130818367004395\n",
      "epoch 20, batch 140, loss = 2.684931516647339\n",
      "epoch 20, batch 150, loss = 2.7482690811157227\n",
      "epoch 20, batch 160, loss = 2.6788506507873535\n",
      "epoch 20, batch 170, loss = 2.7122890949249268\n",
      "epoch 20, batch 180, loss = 2.742401123046875\n",
      "epoch 20, batch 190, loss = 2.75108003616333\n",
      "epoch 20, batch 200, loss = 2.6675853729248047\n",
      "epoch 20, batch 210, loss = 2.7811965942382812\n",
      "epoch 20, batch 220, loss = 2.709160804748535\n",
      "epoch 20, batch 230, loss = 2.6829757690429688\n",
      "epoch 20, batch 240, loss = 2.7428574562072754\n",
      "epoch 20, batch 250, loss = 2.798161029815674\n",
      "epoch 20, batch 260, loss = 2.6758668422698975\n",
      "epoch 20, batch 270, loss = 2.7217206954956055\n",
      "epoch 20, batch 280, loss = 2.702171802520752\n",
      "epoch 21, batch 0, loss = 2.656743049621582\n",
      "epoch 21, batch 10, loss = 2.7238171100616455\n",
      "epoch 21, batch 20, loss = 2.7197039127349854\n",
      "epoch 21, batch 30, loss = 2.634045124053955\n",
      "epoch 21, batch 40, loss = 2.738281488418579\n",
      "epoch 21, batch 50, loss = 2.695526599884033\n",
      "epoch 21, batch 60, loss = 2.6553704738616943\n",
      "epoch 21, batch 70, loss = 2.662346363067627\n",
      "epoch 21, batch 80, loss = 2.7076401710510254\n",
      "epoch 21, batch 90, loss = 2.6905910968780518\n",
      "epoch 21, batch 100, loss = 2.684086561203003\n",
      "epoch 21, batch 110, loss = 2.67185640335083\n",
      "epoch 21, batch 120, loss = 2.696230411529541\n",
      "epoch 21, batch 130, loss = 2.6969823837280273\n",
      "epoch 21, batch 140, loss = 2.6964406967163086\n",
      "epoch 21, batch 150, loss = 2.7382447719573975\n",
      "epoch 21, batch 160, loss = 2.692403554916382\n",
      "epoch 21, batch 170, loss = 2.6663708686828613\n",
      "epoch 21, batch 180, loss = 2.7071404457092285\n",
      "epoch 21, batch 190, loss = 2.699833393096924\n",
      "epoch 21, batch 200, loss = 2.7745394706726074\n",
      "epoch 21, batch 210, loss = 2.7178993225097656\n",
      "epoch 21, batch 220, loss = 2.7127411365509033\n",
      "epoch 21, batch 230, loss = 2.711726188659668\n",
      "epoch 21, batch 240, loss = 2.737299680709839\n",
      "epoch 21, batch 250, loss = 2.735062599182129\n",
      "epoch 21, batch 260, loss = 2.7518978118896484\n",
      "epoch 21, batch 270, loss = 2.6781225204467773\n",
      "epoch 21, batch 280, loss = 2.7823739051818848\n",
      "epoch 22, batch 0, loss = 2.710425615310669\n",
      "epoch 22, batch 10, loss = 2.7298684120178223\n",
      "epoch 22, batch 20, loss = 2.7174949645996094\n",
      "epoch 22, batch 30, loss = 2.6950621604919434\n",
      "epoch 22, batch 40, loss = 2.7093348503112793\n",
      "epoch 22, batch 50, loss = 2.6796226501464844\n",
      "epoch 22, batch 60, loss = 2.688650131225586\n",
      "epoch 22, batch 70, loss = 2.6674013137817383\n",
      "epoch 22, batch 80, loss = 2.7369730472564697\n",
      "epoch 22, batch 90, loss = 2.7585887908935547\n",
      "epoch 22, batch 100, loss = 2.736002206802368\n",
      "epoch 22, batch 110, loss = 2.7465782165527344\n",
      "epoch 22, batch 120, loss = 2.6896138191223145\n",
      "epoch 22, batch 130, loss = 2.64064621925354\n",
      "epoch 22, batch 140, loss = 2.7002615928649902\n",
      "epoch 22, batch 150, loss = 2.723195791244507\n",
      "epoch 22, batch 160, loss = 2.685332775115967\n",
      "epoch 22, batch 170, loss = 2.721928834915161\n",
      "epoch 22, batch 180, loss = 2.7194032669067383\n",
      "epoch 22, batch 190, loss = 2.6964735984802246\n",
      "epoch 22, batch 200, loss = 2.649998188018799\n",
      "epoch 22, batch 210, loss = 2.734288215637207\n",
      "epoch 22, batch 220, loss = 2.7089133262634277\n",
      "epoch 22, batch 230, loss = 2.7207603454589844\n",
      "epoch 22, batch 240, loss = 2.735246419906616\n",
      "epoch 22, batch 250, loss = 2.763169765472412\n",
      "epoch 22, batch 260, loss = 2.723587989807129\n",
      "epoch 22, batch 270, loss = 2.7497763633728027\n",
      "epoch 22, batch 280, loss = 2.629563808441162\n",
      "epoch 23, batch 0, loss = 2.6429920196533203\n",
      "epoch 23, batch 10, loss = 2.7585654258728027\n",
      "epoch 23, batch 20, loss = 2.7230215072631836\n",
      "epoch 23, batch 30, loss = 2.671250104904175\n",
      "epoch 23, batch 40, loss = 2.711303234100342\n",
      "epoch 23, batch 50, loss = 2.6531600952148438\n",
      "epoch 23, batch 60, loss = 2.6789772510528564\n",
      "epoch 23, batch 70, loss = 2.6851537227630615\n",
      "epoch 23, batch 80, loss = 2.708775043487549\n",
      "epoch 23, batch 90, loss = 2.665820598602295\n",
      "epoch 23, batch 100, loss = 2.651628017425537\n",
      "epoch 23, batch 110, loss = 2.6984639167785645\n",
      "epoch 23, batch 120, loss = 2.73762845993042\n",
      "epoch 23, batch 130, loss = 2.685438632965088\n",
      "epoch 23, batch 140, loss = 2.6658520698547363\n",
      "epoch 23, batch 150, loss = 2.697810649871826\n",
      "epoch 23, batch 160, loss = 2.7292227745056152\n",
      "epoch 23, batch 170, loss = 2.7175769805908203\n",
      "epoch 23, batch 180, loss = 2.7144527435302734\n",
      "epoch 23, batch 190, loss = 2.6768131256103516\n",
      "epoch 23, batch 200, loss = 2.7187275886535645\n",
      "epoch 23, batch 210, loss = 2.7423272132873535\n",
      "epoch 23, batch 220, loss = 2.6981492042541504\n",
      "epoch 23, batch 230, loss = 2.7605879306793213\n",
      "epoch 23, batch 240, loss = 2.684652328491211\n",
      "epoch 23, batch 250, loss = 2.7256102561950684\n",
      "epoch 23, batch 260, loss = 2.673260450363159\n",
      "epoch 23, batch 270, loss = 2.716247081756592\n",
      "epoch 23, batch 280, loss = 2.70518159866333\n",
      "epoch 24, batch 0, loss = 2.677417278289795\n",
      "epoch 24, batch 10, loss = 2.7644805908203125\n",
      "epoch 24, batch 20, loss = 2.672440528869629\n",
      "epoch 24, batch 30, loss = 2.715359926223755\n",
      "epoch 24, batch 40, loss = 2.7540082931518555\n",
      "epoch 24, batch 50, loss = 2.723731279373169\n",
      "epoch 24, batch 60, loss = 2.707655429840088\n",
      "epoch 24, batch 70, loss = 2.6903398036956787\n",
      "epoch 24, batch 80, loss = 2.716986894607544\n",
      "epoch 24, batch 90, loss = 2.6537461280822754\n",
      "epoch 24, batch 100, loss = 2.708749771118164\n",
      "epoch 24, batch 110, loss = 2.719149112701416\n",
      "epoch 24, batch 120, loss = 2.6941757202148438\n",
      "epoch 24, batch 130, loss = 2.720832347869873\n",
      "epoch 24, batch 140, loss = 2.763533592224121\n",
      "epoch 24, batch 150, loss = 2.7156553268432617\n",
      "epoch 24, batch 160, loss = 2.730071783065796\n",
      "epoch 24, batch 170, loss = 2.738645553588867\n",
      "epoch 24, batch 180, loss = 2.680799722671509\n",
      "epoch 24, batch 190, loss = 2.7360212802886963\n",
      "epoch 24, batch 200, loss = 2.6983072757720947\n",
      "epoch 24, batch 210, loss = 2.626471996307373\n",
      "epoch 24, batch 220, loss = 2.712048053741455\n",
      "epoch 24, batch 230, loss = 2.7214016914367676\n",
      "epoch 24, batch 240, loss = 2.6666042804718018\n",
      "epoch 24, batch 250, loss = 2.7056922912597656\n",
      "epoch 24, batch 260, loss = 2.72873592376709\n",
      "epoch 24, batch 270, loss = 2.711810827255249\n",
      "epoch 24, batch 280, loss = 2.678377151489258\n",
      "epoch 25, batch 0, loss = 2.694460868835449\n",
      "epoch 25, batch 10, loss = 2.6821749210357666\n",
      "epoch 25, batch 20, loss = 2.711361885070801\n",
      "epoch 25, batch 30, loss = 2.7103986740112305\n",
      "epoch 25, batch 40, loss = 2.682248592376709\n",
      "epoch 25, batch 50, loss = 2.6992838382720947\n",
      "epoch 25, batch 60, loss = 2.6588921546936035\n",
      "epoch 25, batch 70, loss = 2.6667582988739014\n",
      "epoch 25, batch 80, loss = 2.7344017028808594\n",
      "epoch 25, batch 90, loss = 2.744751453399658\n",
      "epoch 25, batch 100, loss = 2.6988508701324463\n",
      "epoch 25, batch 110, loss = 2.6942362785339355\n",
      "epoch 25, batch 120, loss = 2.6745975017547607\n",
      "epoch 25, batch 130, loss = 2.665215492248535\n",
      "epoch 25, batch 140, loss = 2.752763032913208\n",
      "epoch 25, batch 150, loss = 2.7255923748016357\n",
      "epoch 25, batch 160, loss = 2.695557117462158\n",
      "epoch 25, batch 170, loss = 2.683969736099243\n",
      "epoch 25, batch 180, loss = 2.668327808380127\n",
      "epoch 25, batch 190, loss = 2.736875534057617\n",
      "epoch 25, batch 200, loss = 2.7057390213012695\n",
      "epoch 25, batch 210, loss = 2.6839981079101562\n",
      "epoch 25, batch 220, loss = 2.6767330169677734\n",
      "epoch 25, batch 230, loss = 2.6746604442596436\n",
      "epoch 25, batch 240, loss = 2.6900277137756348\n",
      "epoch 25, batch 250, loss = 2.6928961277008057\n",
      "epoch 25, batch 260, loss = 2.7095894813537598\n",
      "epoch 25, batch 270, loss = 2.7521986961364746\n",
      "epoch 25, batch 280, loss = 2.6789743900299072\n",
      "epoch 26, batch 0, loss = 2.6757760047912598\n",
      "epoch 26, batch 10, loss = 2.668114423751831\n",
      "epoch 26, batch 20, loss = 2.668086051940918\n",
      "epoch 26, batch 30, loss = 2.664111375808716\n",
      "epoch 26, batch 40, loss = 2.6806094646453857\n",
      "epoch 26, batch 50, loss = 2.7035951614379883\n",
      "epoch 26, batch 60, loss = 2.729787826538086\n",
      "epoch 26, batch 70, loss = 2.6637673377990723\n",
      "epoch 26, batch 80, loss = 2.675703525543213\n",
      "epoch 26, batch 90, loss = 2.716965675354004\n",
      "epoch 26, batch 100, loss = 2.6611742973327637\n",
      "epoch 26, batch 110, loss = 2.6597468852996826\n",
      "epoch 26, batch 120, loss = 2.6503148078918457\n",
      "epoch 26, batch 130, loss = 2.699052333831787\n",
      "epoch 26, batch 140, loss = 2.6910207271575928\n",
      "epoch 26, batch 150, loss = 2.6938579082489014\n",
      "epoch 26, batch 160, loss = 2.7104978561401367\n",
      "epoch 26, batch 170, loss = 2.677217960357666\n",
      "epoch 26, batch 180, loss = 2.639427661895752\n",
      "epoch 26, batch 190, loss = 2.714120626449585\n",
      "epoch 26, batch 200, loss = 2.741842746734619\n",
      "epoch 26, batch 210, loss = 2.7246651649475098\n",
      "epoch 26, batch 220, loss = 2.70579195022583\n",
      "epoch 26, batch 230, loss = 2.677213668823242\n",
      "epoch 26, batch 240, loss = 2.6995744705200195\n",
      "epoch 26, batch 250, loss = 2.6745986938476562\n",
      "epoch 26, batch 260, loss = 2.713776111602783\n",
      "epoch 26, batch 270, loss = 2.6537344455718994\n",
      "epoch 26, batch 280, loss = 2.7618637084960938\n",
      "epoch 27, batch 0, loss = 2.6217474937438965\n",
      "epoch 27, batch 10, loss = 2.7164599895477295\n",
      "epoch 27, batch 20, loss = 2.6866931915283203\n",
      "epoch 27, batch 30, loss = 2.6668217182159424\n",
      "epoch 27, batch 40, loss = 2.6778602600097656\n",
      "epoch 27, batch 50, loss = 2.689517021179199\n",
      "epoch 27, batch 60, loss = 2.705425262451172\n",
      "epoch 27, batch 70, loss = 2.653425693511963\n",
      "epoch 27, batch 80, loss = 2.6922507286071777\n",
      "epoch 27, batch 90, loss = 2.744309902191162\n",
      "epoch 27, batch 100, loss = 2.639035701751709\n",
      "epoch 27, batch 110, loss = 2.6900672912597656\n",
      "epoch 27, batch 120, loss = 2.7058043479919434\n",
      "epoch 27, batch 130, loss = 2.658630847930908\n",
      "epoch 27, batch 140, loss = 2.6756591796875\n",
      "epoch 27, batch 150, loss = 2.6796607971191406\n",
      "epoch 27, batch 160, loss = 2.6738839149475098\n",
      "epoch 27, batch 170, loss = 2.760435104370117\n",
      "epoch 27, batch 180, loss = 2.737330913543701\n",
      "epoch 27, batch 190, loss = 2.724470376968384\n",
      "epoch 27, batch 200, loss = 2.6735763549804688\n",
      "epoch 27, batch 210, loss = 2.661787271499634\n",
      "epoch 27, batch 220, loss = 2.6905007362365723\n",
      "epoch 27, batch 230, loss = 2.6951942443847656\n",
      "epoch 27, batch 240, loss = 2.733738422393799\n",
      "epoch 27, batch 250, loss = 2.6986136436462402\n",
      "epoch 27, batch 260, loss = 2.722339153289795\n",
      "epoch 27, batch 270, loss = 2.71962571144104\n",
      "epoch 27, batch 280, loss = 2.6778159141540527\n",
      "epoch 28, batch 0, loss = 2.6401824951171875\n",
      "epoch 28, batch 10, loss = 2.7384591102600098\n",
      "epoch 28, batch 20, loss = 2.6644186973571777\n",
      "epoch 28, batch 30, loss = 2.6732964515686035\n",
      "epoch 28, batch 40, loss = 2.6330783367156982\n",
      "epoch 28, batch 50, loss = 2.6687140464782715\n",
      "epoch 28, batch 60, loss = 2.6528396606445312\n",
      "epoch 28, batch 70, loss = 2.64715838432312\n",
      "epoch 28, batch 80, loss = 2.71414852142334\n",
      "epoch 28, batch 90, loss = 2.680110454559326\n",
      "epoch 28, batch 100, loss = 2.729372024536133\n",
      "epoch 28, batch 110, loss = 2.689436674118042\n",
      "epoch 28, batch 120, loss = 2.699404716491699\n",
      "epoch 28, batch 130, loss = 2.705296754837036\n",
      "epoch 28, batch 140, loss = 2.6749253273010254\n",
      "epoch 28, batch 150, loss = 2.6736485958099365\n",
      "epoch 28, batch 160, loss = 2.6771645545959473\n",
      "epoch 28, batch 170, loss = 2.688936471939087\n",
      "epoch 28, batch 180, loss = 2.709102153778076\n",
      "epoch 28, batch 190, loss = 2.702239513397217\n",
      "epoch 28, batch 200, loss = 2.6933436393737793\n",
      "epoch 28, batch 210, loss = 2.690351963043213\n",
      "epoch 28, batch 220, loss = 2.709584951400757\n",
      "epoch 28, batch 230, loss = 2.7283265590667725\n",
      "epoch 28, batch 240, loss = 2.6979241371154785\n",
      "epoch 28, batch 250, loss = 2.747997283935547\n",
      "epoch 28, batch 260, loss = 2.6635992527008057\n",
      "epoch 28, batch 270, loss = 2.718109369277954\n",
      "epoch 28, batch 280, loss = 2.7239503860473633\n",
      "epoch 29, batch 0, loss = 2.737002372741699\n",
      "epoch 29, batch 10, loss = 2.7345449924468994\n",
      "epoch 29, batch 20, loss = 2.6732559204101562\n",
      "epoch 29, batch 30, loss = 2.7041869163513184\n",
      "epoch 29, batch 40, loss = 2.6454992294311523\n",
      "epoch 29, batch 50, loss = 2.7037577629089355\n",
      "epoch 29, batch 60, loss = 2.692228078842163\n",
      "epoch 29, batch 70, loss = 2.6997549533843994\n",
      "epoch 29, batch 80, loss = 2.680100440979004\n",
      "epoch 29, batch 90, loss = 2.6562767028808594\n",
      "epoch 29, batch 100, loss = 2.7229065895080566\n",
      "epoch 29, batch 110, loss = 2.686520576477051\n",
      "epoch 29, batch 120, loss = 2.6321098804473877\n",
      "epoch 29, batch 130, loss = 2.6647725105285645\n",
      "epoch 29, batch 140, loss = 2.7005019187927246\n",
      "epoch 29, batch 150, loss = 2.658071279525757\n",
      "epoch 29, batch 160, loss = 2.713184118270874\n",
      "epoch 29, batch 170, loss = 2.63908052444458\n",
      "epoch 29, batch 180, loss = 2.6638364791870117\n",
      "epoch 29, batch 190, loss = 2.6278481483459473\n",
      "epoch 29, batch 200, loss = 2.6729846000671387\n",
      "epoch 29, batch 210, loss = 2.6785874366760254\n",
      "epoch 29, batch 220, loss = 2.68046498298645\n",
      "epoch 29, batch 230, loss = 2.746974468231201\n",
      "epoch 29, batch 240, loss = 2.7075438499450684\n",
      "epoch 29, batch 250, loss = 2.6879048347473145\n",
      "epoch 29, batch 260, loss = 2.700322151184082\n",
      "epoch 29, batch 270, loss = 2.654784679412842\n",
      "epoch 29, batch 280, loss = 2.644928455352783\n",
      "epoch 30, batch 0, loss = 2.6487224102020264\n",
      "epoch 30, batch 10, loss = 2.653775453567505\n",
      "epoch 30, batch 20, loss = 2.6361336708068848\n",
      "epoch 30, batch 30, loss = 2.6892127990722656\n",
      "epoch 30, batch 40, loss = 2.6709437370300293\n",
      "epoch 30, batch 50, loss = 2.6545584201812744\n",
      "epoch 30, batch 60, loss = 2.620232582092285\n",
      "epoch 30, batch 70, loss = 2.661248207092285\n",
      "epoch 30, batch 80, loss = 2.67303466796875\n",
      "epoch 30, batch 90, loss = 2.6693756580352783\n",
      "epoch 30, batch 100, loss = 2.6820437908172607\n",
      "epoch 30, batch 110, loss = 2.692742347717285\n",
      "epoch 30, batch 120, loss = 2.7013602256774902\n",
      "epoch 30, batch 130, loss = 2.6296043395996094\n",
      "epoch 30, batch 140, loss = 2.6691925525665283\n",
      "epoch 30, batch 150, loss = 2.728538751602173\n",
      "epoch 30, batch 160, loss = 2.617446184158325\n",
      "epoch 30, batch 170, loss = 2.669757843017578\n",
      "epoch 30, batch 180, loss = 2.598539352416992\n",
      "epoch 30, batch 190, loss = 2.715898275375366\n",
      "epoch 30, batch 200, loss = 2.649707317352295\n",
      "epoch 30, batch 210, loss = 2.6715030670166016\n",
      "epoch 30, batch 220, loss = 2.673408269882202\n",
      "epoch 30, batch 230, loss = 2.6678285598754883\n",
      "epoch 30, batch 240, loss = 2.7143614292144775\n",
      "epoch 30, batch 250, loss = 2.7192530632019043\n",
      "epoch 30, batch 260, loss = 2.6771445274353027\n",
      "epoch 30, batch 270, loss = 2.6852993965148926\n",
      "epoch 30, batch 280, loss = 2.701993942260742\n",
      "epoch 31, batch 0, loss = 2.6500697135925293\n",
      "epoch 31, batch 10, loss = 2.7018373012542725\n",
      "epoch 31, batch 20, loss = 2.6477179527282715\n",
      "epoch 31, batch 30, loss = 2.668564796447754\n",
      "epoch 31, batch 40, loss = 2.660036087036133\n",
      "epoch 31, batch 50, loss = 2.678968906402588\n",
      "epoch 31, batch 60, loss = 2.6763229370117188\n",
      "epoch 31, batch 70, loss = 2.6968324184417725\n",
      "epoch 31, batch 80, loss = 2.7094759941101074\n",
      "epoch 31, batch 90, loss = 2.68875789642334\n",
      "epoch 31, batch 100, loss = 2.693850040435791\n",
      "epoch 31, batch 110, loss = 2.694885492324829\n",
      "epoch 31, batch 120, loss = 2.77229642868042\n",
      "epoch 31, batch 130, loss = 2.7083282470703125\n",
      "epoch 31, batch 140, loss = 2.6685714721679688\n",
      "epoch 31, batch 150, loss = 2.692519426345825\n",
      "epoch 31, batch 160, loss = 2.697396993637085\n",
      "epoch 31, batch 170, loss = 2.6551966667175293\n",
      "epoch 31, batch 180, loss = 2.709506034851074\n",
      "epoch 31, batch 190, loss = 2.6851632595062256\n",
      "epoch 31, batch 200, loss = 2.685227394104004\n",
      "epoch 31, batch 210, loss = 2.6951606273651123\n",
      "epoch 31, batch 220, loss = 2.717139720916748\n",
      "epoch 31, batch 230, loss = 2.6970715522766113\n",
      "epoch 31, batch 240, loss = 2.7110612392425537\n",
      "epoch 31, batch 250, loss = 2.7178590297698975\n",
      "epoch 31, batch 260, loss = 2.681546211242676\n",
      "epoch 31, batch 270, loss = 2.6947336196899414\n",
      "epoch 31, batch 280, loss = 2.641047716140747\n",
      "epoch 32, batch 0, loss = 2.6871533393859863\n",
      "epoch 32, batch 10, loss = 2.6461703777313232\n",
      "epoch 32, batch 20, loss = 2.6461963653564453\n",
      "epoch 32, batch 30, loss = 2.690951347351074\n",
      "epoch 32, batch 40, loss = 2.640378952026367\n",
      "epoch 32, batch 50, loss = 2.69012451171875\n",
      "epoch 32, batch 60, loss = 2.7015206813812256\n",
      "epoch 32, batch 70, loss = 2.6755504608154297\n",
      "epoch 32, batch 80, loss = 2.715963840484619\n",
      "epoch 32, batch 90, loss = 2.68135404586792\n",
      "epoch 32, batch 100, loss = 2.640814781188965\n",
      "epoch 32, batch 110, loss = 2.6596474647521973\n",
      "epoch 32, batch 120, loss = 2.6719484329223633\n",
      "epoch 32, batch 130, loss = 2.6870100498199463\n",
      "epoch 32, batch 140, loss = 2.702932834625244\n",
      "epoch 32, batch 150, loss = 2.7326958179473877\n",
      "epoch 32, batch 160, loss = 2.7240517139434814\n",
      "epoch 32, batch 170, loss = 2.647573947906494\n",
      "epoch 32, batch 180, loss = 2.7149431705474854\n",
      "epoch 32, batch 190, loss = 2.6485655307769775\n",
      "epoch 32, batch 200, loss = 2.659885883331299\n",
      "epoch 32, batch 210, loss = 2.6920528411865234\n",
      "epoch 32, batch 220, loss = 2.6931281089782715\n",
      "epoch 32, batch 230, loss = 2.654524326324463\n",
      "epoch 32, batch 240, loss = 2.656965732574463\n",
      "epoch 32, batch 250, loss = 2.6185784339904785\n",
      "epoch 32, batch 260, loss = 2.66265606880188\n",
      "epoch 32, batch 270, loss = 2.6597166061401367\n",
      "epoch 32, batch 280, loss = 2.624662399291992\n",
      "epoch 33, batch 0, loss = 2.6476597785949707\n",
      "epoch 33, batch 10, loss = 2.6118063926696777\n",
      "epoch 33, batch 20, loss = 2.5998377799987793\n",
      "epoch 33, batch 30, loss = 2.685133934020996\n",
      "epoch 33, batch 40, loss = 2.692760467529297\n",
      "epoch 33, batch 50, loss = 2.6627678871154785\n",
      "epoch 33, batch 60, loss = 2.647188186645508\n",
      "epoch 33, batch 70, loss = 2.6432619094848633\n",
      "epoch 33, batch 80, loss = 2.7169620990753174\n",
      "epoch 33, batch 90, loss = 2.6987738609313965\n",
      "epoch 33, batch 100, loss = 2.669858932495117\n",
      "epoch 33, batch 110, loss = 2.651531457901001\n",
      "epoch 33, batch 120, loss = 2.7124128341674805\n",
      "epoch 33, batch 130, loss = 2.652348279953003\n",
      "epoch 33, batch 140, loss = 2.6648902893066406\n",
      "epoch 33, batch 150, loss = 2.711779832839966\n",
      "epoch 33, batch 160, loss = 2.6824681758880615\n",
      "epoch 33, batch 170, loss = 2.716860055923462\n",
      "epoch 33, batch 180, loss = 2.7026119232177734\n",
      "epoch 33, batch 190, loss = 2.653569221496582\n",
      "epoch 33, batch 200, loss = 2.6663007736206055\n",
      "epoch 33, batch 210, loss = 2.719076633453369\n",
      "epoch 33, batch 220, loss = 2.7113561630249023\n",
      "epoch 33, batch 230, loss = 2.659482955932617\n",
      "epoch 33, batch 240, loss = 2.633881092071533\n",
      "epoch 33, batch 250, loss = 2.682464361190796\n",
      "epoch 33, batch 260, loss = 2.7044501304626465\n",
      "epoch 33, batch 270, loss = 2.6560940742492676\n",
      "epoch 33, batch 280, loss = 2.690764904022217\n",
      "epoch 34, batch 0, loss = 2.621995687484741\n",
      "epoch 34, batch 10, loss = 2.6722049713134766\n",
      "epoch 34, batch 20, loss = 2.65524959564209\n",
      "epoch 34, batch 30, loss = 2.6497199535369873\n",
      "epoch 34, batch 40, loss = 2.6926944255828857\n",
      "epoch 34, batch 50, loss = 2.6747093200683594\n",
      "epoch 34, batch 60, loss = 2.700728416442871\n",
      "epoch 34, batch 70, loss = 2.6775503158569336\n",
      "epoch 34, batch 80, loss = 2.68589448928833\n",
      "epoch 34, batch 90, loss = 2.6522929668426514\n",
      "epoch 34, batch 100, loss = 2.6503806114196777\n",
      "epoch 34, batch 110, loss = 2.6488237380981445\n",
      "epoch 34, batch 120, loss = 2.6711864471435547\n",
      "epoch 34, batch 130, loss = 2.6634297370910645\n",
      "epoch 34, batch 140, loss = 2.6908178329467773\n",
      "epoch 34, batch 150, loss = 2.6334874629974365\n",
      "epoch 34, batch 160, loss = 2.6730034351348877\n",
      "epoch 34, batch 170, loss = 2.7120680809020996\n",
      "epoch 34, batch 180, loss = 2.7002954483032227\n",
      "epoch 34, batch 190, loss = 2.7056288719177246\n",
      "epoch 34, batch 200, loss = 2.6739559173583984\n",
      "epoch 34, batch 210, loss = 2.6913070678710938\n",
      "epoch 34, batch 220, loss = 2.64388370513916\n",
      "epoch 34, batch 230, loss = 2.680091619491577\n",
      "epoch 34, batch 240, loss = 2.6765568256378174\n",
      "epoch 34, batch 250, loss = 2.694697141647339\n",
      "epoch 34, batch 260, loss = 2.710181951522827\n",
      "epoch 34, batch 270, loss = 2.699018955230713\n",
      "epoch 34, batch 280, loss = 2.743478298187256\n",
      "epoch 35, batch 0, loss = 2.6218318939208984\n",
      "epoch 35, batch 10, loss = 2.6970248222351074\n",
      "epoch 35, batch 20, loss = 2.623147487640381\n",
      "epoch 35, batch 30, loss = 2.69851016998291\n",
      "epoch 35, batch 40, loss = 2.6539273262023926\n",
      "epoch 35, batch 50, loss = 2.6364169120788574\n",
      "epoch 35, batch 60, loss = 2.691171646118164\n",
      "epoch 35, batch 70, loss = 2.612534999847412\n",
      "epoch 35, batch 80, loss = 2.6052279472351074\n",
      "epoch 35, batch 90, loss = 2.61137056350708\n",
      "epoch 35, batch 100, loss = 2.6590020656585693\n",
      "epoch 35, batch 110, loss = 2.6436104774475098\n",
      "epoch 35, batch 120, loss = 2.685046672821045\n",
      "epoch 35, batch 130, loss = 2.6384658813476562\n",
      "epoch 35, batch 140, loss = 2.684723377227783\n",
      "epoch 35, batch 150, loss = 2.6690220832824707\n",
      "epoch 35, batch 160, loss = 2.630056142807007\n",
      "epoch 35, batch 170, loss = 2.6867003440856934\n",
      "epoch 35, batch 180, loss = 2.689976930618286\n",
      "epoch 35, batch 190, loss = 2.658662796020508\n",
      "epoch 35, batch 200, loss = 2.6733388900756836\n",
      "epoch 35, batch 210, loss = 2.6239004135131836\n",
      "epoch 35, batch 220, loss = 2.6354987621307373\n",
      "epoch 35, batch 230, loss = 2.71977162361145\n",
      "epoch 35, batch 240, loss = 2.702608108520508\n",
      "epoch 35, batch 250, loss = 2.6764707565307617\n",
      "epoch 35, batch 260, loss = 2.7038402557373047\n",
      "epoch 35, batch 270, loss = 2.692631483078003\n",
      "epoch 35, batch 280, loss = 2.665804862976074\n",
      "epoch 36, batch 0, loss = 2.6135926246643066\n",
      "epoch 36, batch 10, loss = 2.6412999629974365\n",
      "epoch 36, batch 20, loss = 2.6432313919067383\n",
      "epoch 36, batch 30, loss = 2.672238349914551\n",
      "epoch 36, batch 40, loss = 2.703409194946289\n",
      "epoch 36, batch 50, loss = 2.717860698699951\n",
      "epoch 36, batch 60, loss = 2.6764421463012695\n",
      "epoch 36, batch 70, loss = 2.590282917022705\n",
      "epoch 36, batch 80, loss = 2.708878517150879\n",
      "epoch 36, batch 90, loss = 2.666424512863159\n",
      "epoch 36, batch 100, loss = 2.6145882606506348\n",
      "epoch 36, batch 110, loss = 2.7153897285461426\n",
      "epoch 36, batch 120, loss = 2.7181994915008545\n",
      "epoch 36, batch 130, loss = 2.689303398132324\n",
      "epoch 36, batch 140, loss = 2.636457920074463\n",
      "epoch 36, batch 150, loss = 2.684096574783325\n",
      "epoch 36, batch 160, loss = 2.6409897804260254\n",
      "epoch 36, batch 170, loss = 2.6725549697875977\n",
      "epoch 36, batch 180, loss = 2.657471179962158\n",
      "epoch 36, batch 190, loss = 2.673552989959717\n",
      "epoch 36, batch 200, loss = 2.6406426429748535\n",
      "epoch 36, batch 210, loss = 2.723299026489258\n",
      "epoch 36, batch 220, loss = 2.6577224731445312\n",
      "epoch 36, batch 230, loss = 2.6878490447998047\n",
      "epoch 36, batch 240, loss = 2.667512893676758\n",
      "epoch 36, batch 250, loss = 2.6567134857177734\n",
      "epoch 36, batch 260, loss = 2.6643080711364746\n",
      "epoch 36, batch 270, loss = 2.675184726715088\n",
      "epoch 36, batch 280, loss = 2.677259922027588\n",
      "epoch 37, batch 0, loss = 2.675158977508545\n",
      "epoch 37, batch 10, loss = 2.613483428955078\n",
      "epoch 37, batch 20, loss = 2.5975382328033447\n",
      "epoch 37, batch 30, loss = 2.6405386924743652\n",
      "epoch 37, batch 40, loss = 2.6486527919769287\n",
      "epoch 37, batch 50, loss = 2.6566519737243652\n",
      "epoch 37, batch 60, loss = 2.6543145179748535\n",
      "epoch 37, batch 70, loss = 2.6785123348236084\n",
      "epoch 37, batch 80, loss = 2.6765036582946777\n",
      "epoch 37, batch 90, loss = 2.648869514465332\n",
      "epoch 37, batch 100, loss = 2.745795249938965\n",
      "epoch 37, batch 110, loss = 2.597465991973877\n",
      "epoch 37, batch 120, loss = 2.7056522369384766\n",
      "epoch 37, batch 130, loss = 2.6714272499084473\n",
      "epoch 37, batch 140, loss = 2.6680750846862793\n",
      "epoch 37, batch 150, loss = 2.687808036804199\n",
      "epoch 37, batch 160, loss = 2.6934309005737305\n",
      "epoch 37, batch 170, loss = 2.6573290824890137\n",
      "epoch 37, batch 180, loss = 2.6276328563690186\n",
      "epoch 37, batch 190, loss = 2.656947135925293\n",
      "epoch 37, batch 200, loss = 2.7131597995758057\n",
      "epoch 37, batch 210, loss = 2.7089736461639404\n",
      "epoch 37, batch 220, loss = 2.65847110748291\n",
      "epoch 37, batch 230, loss = 2.695441246032715\n",
      "epoch 37, batch 240, loss = 2.660282611846924\n",
      "epoch 37, batch 250, loss = 2.6895642280578613\n",
      "epoch 37, batch 260, loss = 2.657888174057007\n",
      "epoch 37, batch 270, loss = 2.6854186058044434\n",
      "epoch 37, batch 280, loss = 2.6386265754699707\n",
      "epoch 38, batch 0, loss = 2.6408891677856445\n",
      "epoch 38, batch 10, loss = 2.6301474571228027\n",
      "epoch 38, batch 20, loss = 2.6535913944244385\n",
      "epoch 38, batch 30, loss = 2.678412437438965\n",
      "epoch 38, batch 40, loss = 2.6886355876922607\n",
      "epoch 38, batch 50, loss = 2.6380786895751953\n",
      "epoch 38, batch 60, loss = 2.6357064247131348\n",
      "epoch 38, batch 70, loss = 2.615570068359375\n",
      "epoch 38, batch 80, loss = 2.6064834594726562\n",
      "epoch 38, batch 90, loss = 2.6729512214660645\n",
      "epoch 38, batch 100, loss = 2.648603677749634\n",
      "epoch 38, batch 110, loss = 2.68681001663208\n",
      "epoch 38, batch 120, loss = 2.6552138328552246\n",
      "epoch 38, batch 130, loss = 2.6632473468780518\n",
      "epoch 38, batch 140, loss = 2.7056186199188232\n",
      "epoch 38, batch 150, loss = 2.6056435108184814\n",
      "epoch 38, batch 160, loss = 2.666085720062256\n",
      "epoch 38, batch 170, loss = 2.6825413703918457\n",
      "epoch 38, batch 180, loss = 2.63151478767395\n",
      "epoch 38, batch 190, loss = 2.680978298187256\n",
      "epoch 38, batch 200, loss = 2.676450252532959\n",
      "epoch 38, batch 210, loss = 2.6575114727020264\n",
      "epoch 38, batch 220, loss = 2.611379623413086\n",
      "epoch 38, batch 230, loss = 2.678530216217041\n",
      "epoch 38, batch 240, loss = 2.617114305496216\n",
      "epoch 38, batch 250, loss = 2.6024320125579834\n",
      "epoch 38, batch 260, loss = 2.6984810829162598\n",
      "epoch 38, batch 270, loss = 2.678908348083496\n",
      "epoch 38, batch 280, loss = 2.59458589553833\n",
      "epoch 39, batch 0, loss = 2.625119209289551\n",
      "epoch 39, batch 10, loss = 2.6109209060668945\n",
      "epoch 39, batch 20, loss = 2.646848201751709\n",
      "epoch 39, batch 30, loss = 2.7223899364471436\n",
      "epoch 39, batch 40, loss = 2.630006790161133\n",
      "epoch 39, batch 50, loss = 2.6177120208740234\n",
      "epoch 39, batch 60, loss = 2.7121989727020264\n",
      "epoch 39, batch 70, loss = 2.6586151123046875\n",
      "epoch 39, batch 80, loss = 2.665822744369507\n",
      "epoch 39, batch 90, loss = 2.6824400424957275\n",
      "epoch 39, batch 100, loss = 2.665907382965088\n",
      "epoch 39, batch 110, loss = 2.6277847290039062\n",
      "epoch 39, batch 120, loss = 2.63338041305542\n",
      "epoch 39, batch 130, loss = 2.6763126850128174\n",
      "epoch 39, batch 140, loss = 2.642401695251465\n",
      "epoch 39, batch 150, loss = 2.648505210876465\n",
      "epoch 39, batch 160, loss = 2.6651015281677246\n",
      "epoch 39, batch 170, loss = 2.6470835208892822\n",
      "epoch 39, batch 180, loss = 2.690124034881592\n",
      "epoch 39, batch 190, loss = 2.638547420501709\n",
      "epoch 39, batch 200, loss = 2.6716489791870117\n",
      "epoch 39, batch 210, loss = 2.6847035884857178\n",
      "epoch 39, batch 220, loss = 2.6327078342437744\n",
      "epoch 39, batch 230, loss = 2.661128044128418\n",
      "epoch 39, batch 240, loss = 2.641300678253174\n",
      "epoch 39, batch 250, loss = 2.6475086212158203\n",
      "epoch 39, batch 260, loss = 2.627622604370117\n",
      "epoch 39, batch 270, loss = 2.649468183517456\n",
      "epoch 39, batch 280, loss = 2.6965999603271484\n",
      "epoch 40, batch 0, loss = 2.6040849685668945\n",
      "epoch 40, batch 10, loss = 2.6419787406921387\n",
      "epoch 40, batch 20, loss = 2.6500983238220215\n",
      "epoch 40, batch 30, loss = 2.6765036582946777\n",
      "epoch 40, batch 40, loss = 2.6182985305786133\n",
      "epoch 40, batch 50, loss = 2.635406732559204\n",
      "epoch 40, batch 60, loss = 2.677961826324463\n",
      "epoch 40, batch 70, loss = 2.6680972576141357\n",
      "epoch 40, batch 80, loss = 2.613666534423828\n",
      "epoch 40, batch 90, loss = 2.650747060775757\n",
      "epoch 40, batch 100, loss = 2.6358492374420166\n",
      "epoch 40, batch 110, loss = 2.628572702407837\n",
      "epoch 40, batch 120, loss = 2.700918674468994\n",
      "epoch 40, batch 130, loss = 2.6928114891052246\n",
      "epoch 40, batch 140, loss = 2.6420557498931885\n",
      "epoch 40, batch 150, loss = 2.6728532314300537\n",
      "epoch 40, batch 160, loss = 2.642015218734741\n",
      "epoch 40, batch 170, loss = 2.6178455352783203\n",
      "epoch 40, batch 180, loss = 2.631096363067627\n",
      "epoch 40, batch 190, loss = 2.673748254776001\n",
      "epoch 40, batch 200, loss = 2.6746065616607666\n",
      "epoch 40, batch 210, loss = 2.7435333728790283\n",
      "epoch 40, batch 220, loss = 2.65322208404541\n",
      "epoch 40, batch 230, loss = 2.685518980026245\n",
      "epoch 40, batch 240, loss = 2.662013053894043\n",
      "epoch 40, batch 250, loss = 2.661590099334717\n",
      "epoch 40, batch 260, loss = 2.6682920455932617\n",
      "epoch 40, batch 270, loss = 2.69023060798645\n",
      "epoch 40, batch 280, loss = 2.6480798721313477\n",
      "535.2391254901886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16ae76064d0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "device = torch.device(\"cuda\")\n",
    "# device = torch.device(\"cpu\")  # If no GPU on the machine\n",
    "\n",
    "# train_id = np.random.choice(len(dat), 10000)\n",
    "# train = [dat[i] for i in train_id]\n",
    "train = dat\n",
    "\n",
    "n = len(train)\n",
    "n_hidden = 256\n",
    "nepoch = 41\n",
    "bs = 256\n",
    "\n",
    "rnn = RNN(charset_size, n_hidden)\n",
    "rnn = rnn.to(device=device)\n",
    "opt = torch.optim.Adam(rnn.parameters(), lr=0.001)\n",
    "train_ind = np.arange(n)\n",
    "lossfn = nn.NLLLoss(reduction=\"none\")\n",
    "losses = []\n",
    "\n",
    "t1 = time.time()\n",
    "for k in range(nepoch):\n",
    "    np.random.shuffle(train_ind)\n",
    "    # Update on mini-batches\n",
    "    for j in range(0, n, bs):\n",
    "        # Create mini-batch\n",
    "        ind = train_ind[j:(j + bs)]\n",
    "        mb = [train[i] for i in ind]\n",
    "        mb_size = len(mb)\n",
    "        input, actual_len, target = names2tensor(mb)  # input是[max_名字长度×名字数量(bs)×charset_size]的三维tensor  actual_len是[bs]的一维 target是[max_名字长度×名字数量(bs)]的二维tensor  \n",
    "        input = input.to(device=device)\n",
    "        target = target.to(device=device)\n",
    "        max_len = input.shape[0]\n",
    "        hidden = rnn.init_hidden(mb_size).to(device=device)    # 每个名字都是一个序列 需要initial一个hidden\n",
    "        loss = 0.0\n",
    "        for s in range(max_len):    # 对每个时点（每个名字按顺序的索引）进行loss的计算\n",
    "            output, hidden = rnn(input[s], hidden)    # output是[名字数量(bs)×charset_size]的二维tensor hidden是[名字数量(bs)×n_hidden]的二维tensor\n",
    "            loss_s = lossfn(output, target[s])     # target[s]是[名字数量(bs)]的一维tensor  计算出来的loss_s也是[名字数量(bs)]的一维tensor\n",
    "            valid = torch.tensor((s < actual_len).astype(int)).to(device=device)  # 把真实长度小于时点s的损失函数屏蔽\n",
    "            loss = loss + loss_s * valid      # 将s个时点的[名字数量(bs)]loss相加\n",
    "        loss = torch.mean(loss / torch.tensor(actual_len).to(device=device)) # 先对每个名字的loss取平均 最后取bs个名字的平均 得到一个bs的loss\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        if j // bs % 10 == 0:\n",
    "            print(f\"epoch {k}, batch {j // bs}, loss = {loss.item()}\")\n",
    "t2 = time.time()\n",
    "print(t2 - t1)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76a09a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (i2h): Linear(in_features=307, out_features=256, bias=True)\n",
       "  (i2o): Linear(in_features=307, out_features=51, bias=True)\n",
       "  (o2o): Linear(in_features=307, out_features=51, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (logsoftmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(rnn.state_dict(), \"gen_en.pt\")\n",
    "rnn.load_state_dict(torch.load(\"gen_en.pt\", map_location=device))\n",
    "rnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7bec938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "雷斯塔\n"
     ]
    }
   ],
   "source": [
    "family_names = np.unique([name[0] for name in dat])\n",
    "def random_family_name():\n",
    "    return np.random.choice(family_names, 1)[0]  # 在name的名字中抽一个名字的第一个字\n",
    "\n",
    "def random_name(max_len=4):\n",
    "    rnn.eval()\n",
    "    family_name = random_family_name()      # 根据抽中的第一个字生成一个名字，名字长度不超过max_len\n",
    "    input = char2tensor(family_name).to(device=device)\n",
    "    char_ind = [torch.argmax(input).item()]\n",
    "    hidden = rnn.init_hidden(batch_size=1).to(device=device)\n",
    "    for i in range(max_len - 1):\n",
    "        output, hidden = rnn(input, hidden)\n",
    "        ind = torch.argmax(output).item()\n",
    "        if ind == charset_size - 1:\n",
    "            break\n",
    "        char_ind.append(ind)\n",
    "        input.zero_()\n",
    "        input[0, ind] = 1.0\n",
    "    return char_ind\n",
    "\n",
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "ind = random_name(10)\n",
    "print(\"\".join([dict[i] for i in ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "587c6a93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['雷斯塔' '伊斯特拉' '瓦尔德' '耶尔维' '西尔韦斯特罗' '布拉伊尼' '库尔蒂耶'\n",
      " '迪亚科' '拉斯特里' '罗斯塔' '维尔斯' '马尔基奥' '埃斯特拉' '维尔斯'\n",
      " '韦尔尼亚尼' '维尔斯' '马尔基奥' '格拉迪尼' '库尔蒂耶' '尔科' '萨尔瓦尼'\n",
      " '维尔斯' '巴尔巴里尼' '内格雷尔' '克拉斯尼' '伊斯特拉' '德拉斯特' '诺尔贝'\n",
      " '伊斯特拉' '德拉斯特' '马尔基奥' '勒布' '达尔贝' '莱斯特雷' '瓦尔德'\n",
      " '西尔韦斯特罗' '罗斯塔' '托尔托拉' '米拉尔迪' '特里亚尼' '耶尔维' '罗斯塔'\n",
      " '奇卡' '贝尔托拉' '克拉斯尼' '迪亚科' '利亚诺' '亚尔马' '塔尔迪' '耶尔维']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "names = []\n",
    "for i in range(50):\n",
    "    ind = random_name(10)\n",
    "    names.append(\"\".join([dict[i] for i in ind]))\n",
    "np.set_printoptions(linewidth=50)\n",
    "print(np.array(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2543fb4-866d-4fe1-abe4-e9dd3428f2ea",
   "metadata": {},
   "source": [
    "## 📌 核心逻辑解释\n",
    "\n",
    "![LSTM](LSTM.jpg)\n",
    "\n",
    "\n",
    "LSTM 的基本计算逻辑就是：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "i_t &= \\sigma(W_{ii}x_t + W_{hi}h_{t-1} + b_i) &\\text{（输入门）} \\\\\n",
    "f_t &= \\sigma(W_{if}x_t + W_{hf}h_{t-1} + b_f) &\\text{（遗忘门）} \\\\\n",
    "g_t &= \\tanh(W_{ig}x_t + W_{hg}h_{t-1} + b_g) &\\text{（候选更新）} \\\\\n",
    "o_t &= \\sigma(W_{io}x_t + W_{ho}h_{t-1} + b_o) &\\text{（输出门）} \\\\\n",
    "c_t &= f_t \\cdot c_{t-1} + i_t \\cdot g_t &\\text{（细胞状态）} \\\\\n",
    "h_t &= o_t \\cdot \\tanh(c_t) &\\text{（隐藏状态）}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* 你看到我就是完整手动实现了这些计算；\n",
    "* 只用到了最基本的矩阵乘法 `@` 和激活函数 `sigmoid`、`tanh`；\n",
    "* 没有使用 `nn.LSTM`，控制力更强，更适合教学和理解模型底层逻辑。\n",
    "\n",
    "## 参考版本\n",
    "```python\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, input_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input shape: (batch_size=1, input_size)\n",
    "        # LSTM expects input shape: (seq_len=1, batch_size, input_size)\n",
    "        input = input.unsqueeze(0)  # -> (1, 1, input_size)\n",
    "        output, hidden = self.lstm(input, hidden)\n",
    "        output = self.fc(output.squeeze(0))  # squeeze seq_len dim\n",
    "        output = self.dropout(output)\n",
    "        output = self.logsoftmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # LSTM has (h_0, c_0)\n",
    "        h_0 = torch.zeros(1, batch_size, self.hidden_size)\n",
    "        c_0 = torch.zeros(1, batch_size, self.hidden_size)\n",
    "        return (h_0, c_0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f99ed2b-6b6d-45fc-83b9-347f3d0ef065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # 四个门的线性层\n",
    "        self.i2f = nn.Linear(input_size + hidden_size, hidden_size)  # forget gate\n",
    "        self.i2i = nn.Linear(input_size + hidden_size, hidden_size)  # input gate\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, hidden_size)  # output gate\n",
    "        self.i2g = nn.Linear(input_size + hidden_size, hidden_size)  # candidate gate\n",
    "\n",
    "        self.out_layer = nn.Linear(hidden_size, input_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        h_prev, c_prev = hidden  # 分别是上一个时间步的 h 和 c\n",
    "        \n",
    "        # 拼接输入与上一隐藏状态\n",
    "        combined = torch.cat((input, h_prev), dim=1)\n",
    "        \n",
    "        # 四个门的计算\n",
    "        f_t = torch.sigmoid(self.i2f(combined))\n",
    "        i_t = torch.sigmoid(self.i2i(combined))\n",
    "        o_t = torch.sigmoid(self.i2o(combined))\n",
    "        g_t = torch.tanh(self.i2g(combined))\n",
    "        \n",
    "        # 细胞状态更新\n",
    "        c_t = f_t * c_prev + i_t * g_t\n",
    "        \n",
    "        # 隐藏状态更新\n",
    "        h_t = o_t * torch.tanh(c_t)\n",
    "        \n",
    "        # 输出层\n",
    "        output = self.out_layer(h_t)\n",
    "        output = self.dropout(output)\n",
    "        output = self.logsoftmax(output)\n",
    "        \n",
    "        return output, (h_t, c_t)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # 初始化隐藏状态和细胞状态\n",
    "        return (torch.zeros(batch_size, self.hidden_size),\n",
    "                torch.zeros(batch_size, self.hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7444c195-38f8-4a99-ad35-bb8964e6dd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 51])\n",
      "tensor([[-3.7980, -3.9237, -3.9574, -3.9989, -3.9022, -3.9993, -3.8726, -3.8635,\n",
      "         -4.0193, -3.8123, -3.9237, -3.9228, -4.0291, -4.0072, -3.7832, -3.9680,\n",
      "         -3.9796, -4.0067, -3.8826, -3.9180, -3.9001, -3.7777, -3.9703, -3.9432,\n",
      "         -4.0576, -3.9843, -3.8746, -3.9716, -3.9237, -3.9719, -3.9655, -3.8045,\n",
      "         -4.0346, -3.9110, -3.9006, -3.9237, -3.9821, -3.8808, -3.9879, -3.8092,\n",
      "         -4.0674, -3.9435, -3.8847, -4.0273, -3.8630, -4.0622, -3.9579, -3.8586,\n",
      "         -3.9088, -3.9071, -4.0414]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 64\n",
    "lstm = MyLSTM(charset_size, n_hidden)\n",
    "lstm = lstm\n",
    "\n",
    "input = name2tensor(\"斯基\")  # one-hot tensor: (seq_len, 1, charset_size)\n",
    "\n",
    "hidden = lstm.init_hidden(batch_size=1)\n",
    "# 如果你在GPU上训练，需要将 hidden 的每个部分也迁移到 device：\n",
    "hidden = (hidden[0], hidden[1])\n",
    "\n",
    "output, next_hidden = lstm(input[0], hidden)  # 取第一个字符\n",
    "print(output.shape)  # 应为 (1, charset_size)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14d0e199-a8b2-4f81-8f19-6ee49fbad9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch 0, loss = 3.920159339904785\n",
      "epoch 0, batch 10, loss = 3.8167285919189453\n",
      "epoch 0, batch 20, loss = 3.3907968997955322\n",
      "epoch 0, batch 30, loss = 3.292941093444824\n",
      "epoch 0, batch 40, loss = 3.2086362838745117\n",
      "epoch 0, batch 50, loss = 3.1812734603881836\n",
      "epoch 0, batch 60, loss = 3.1704182624816895\n",
      "epoch 0, batch 70, loss = 3.177886962890625\n",
      "epoch 0, batch 80, loss = 3.177851676940918\n",
      "epoch 0, batch 90, loss = 3.146270751953125\n",
      "epoch 0, batch 100, loss = 3.139838695526123\n",
      "epoch 0, batch 110, loss = 3.1474618911743164\n",
      "epoch 0, batch 120, loss = 3.1421828269958496\n",
      "epoch 0, batch 130, loss = 3.080841064453125\n",
      "epoch 0, batch 140, loss = 3.1141881942749023\n",
      "epoch 0, batch 150, loss = 3.097585916519165\n",
      "epoch 0, batch 160, loss = 3.126110792160034\n",
      "epoch 0, batch 170, loss = 3.1021790504455566\n",
      "epoch 0, batch 180, loss = 3.0965919494628906\n",
      "epoch 0, batch 190, loss = 3.0928590297698975\n",
      "epoch 0, batch 200, loss = 3.052140712738037\n",
      "epoch 0, batch 210, loss = 3.052572250366211\n",
      "epoch 0, batch 220, loss = 3.093024253845215\n",
      "epoch 0, batch 230, loss = 3.0448269844055176\n",
      "epoch 0, batch 240, loss = 3.0638833045959473\n",
      "epoch 0, batch 250, loss = 3.053546905517578\n",
      "epoch 0, batch 260, loss = 3.041503429412842\n",
      "epoch 0, batch 270, loss = 3.0173959732055664\n",
      "epoch 0, batch 280, loss = 2.9907877445220947\n",
      "epoch 1, batch 0, loss = 2.9973695278167725\n",
      "epoch 1, batch 10, loss = 3.0121591091156006\n",
      "epoch 1, batch 20, loss = 2.99147367477417\n",
      "epoch 1, batch 30, loss = 2.967151403427124\n",
      "epoch 1, batch 40, loss = 2.975264072418213\n",
      "epoch 1, batch 50, loss = 2.945362091064453\n",
      "epoch 1, batch 60, loss = 2.9557557106018066\n",
      "epoch 1, batch 70, loss = 2.9662933349609375\n",
      "epoch 1, batch 80, loss = 2.97794246673584\n",
      "epoch 1, batch 90, loss = 2.9078927040100098\n",
      "epoch 1, batch 100, loss = 2.9286720752716064\n",
      "epoch 1, batch 110, loss = 2.911647081375122\n",
      "epoch 1, batch 120, loss = 2.917123556137085\n",
      "epoch 1, batch 130, loss = 2.9088659286499023\n",
      "epoch 1, batch 140, loss = 2.910210609436035\n",
      "epoch 1, batch 150, loss = 2.8963890075683594\n",
      "epoch 1, batch 160, loss = 2.887033462524414\n",
      "epoch 1, batch 170, loss = 2.8853414058685303\n",
      "epoch 1, batch 180, loss = 2.906493902206421\n",
      "epoch 1, batch 190, loss = 2.9118356704711914\n",
      "epoch 1, batch 200, loss = 2.955519914627075\n",
      "epoch 1, batch 210, loss = 2.876659393310547\n",
      "epoch 1, batch 220, loss = 2.939359664916992\n",
      "epoch 1, batch 230, loss = 2.876636266708374\n",
      "epoch 1, batch 240, loss = 2.894115686416626\n",
      "epoch 1, batch 250, loss = 2.921360492706299\n",
      "epoch 1, batch 260, loss = 2.9300084114074707\n",
      "epoch 1, batch 270, loss = 2.9101920127868652\n",
      "epoch 1, batch 280, loss = 2.8770668506622314\n",
      "epoch 2, batch 0, loss = 2.9462645053863525\n",
      "epoch 2, batch 10, loss = 2.8162999153137207\n",
      "epoch 2, batch 20, loss = 2.892101764678955\n",
      "epoch 2, batch 30, loss = 2.902738094329834\n",
      "epoch 2, batch 40, loss = 2.8978075981140137\n",
      "epoch 2, batch 50, loss = 2.8943729400634766\n",
      "epoch 2, batch 60, loss = 2.868492364883423\n",
      "epoch 2, batch 70, loss = 2.8870086669921875\n",
      "epoch 2, batch 80, loss = 2.889408588409424\n",
      "epoch 2, batch 90, loss = 2.845881462097168\n",
      "epoch 2, batch 100, loss = 2.8708243370056152\n",
      "epoch 2, batch 110, loss = 2.8997645378112793\n",
      "epoch 2, batch 120, loss = 2.8416147232055664\n",
      "epoch 2, batch 130, loss = 2.8857336044311523\n",
      "epoch 2, batch 140, loss = 2.8386809825897217\n",
      "epoch 2, batch 150, loss = 2.8351094722747803\n",
      "epoch 2, batch 160, loss = 2.8907856941223145\n",
      "epoch 2, batch 170, loss = 2.8285889625549316\n",
      "epoch 2, batch 180, loss = 2.82319712638855\n",
      "epoch 2, batch 190, loss = 2.8532145023345947\n",
      "epoch 2, batch 200, loss = 2.8478565216064453\n",
      "epoch 2, batch 210, loss = 2.824846029281616\n",
      "epoch 2, batch 220, loss = 2.877612590789795\n",
      "epoch 2, batch 230, loss = 2.8886923789978027\n",
      "epoch 2, batch 240, loss = 2.9093589782714844\n",
      "epoch 2, batch 250, loss = 2.8683714866638184\n",
      "epoch 2, batch 260, loss = 2.8929646015167236\n",
      "epoch 2, batch 270, loss = 2.841062307357788\n",
      "epoch 2, batch 280, loss = 2.871812582015991\n",
      "epoch 3, batch 0, loss = 2.8262596130371094\n",
      "epoch 3, batch 10, loss = 2.867825984954834\n",
      "epoch 3, batch 20, loss = 2.8789453506469727\n",
      "epoch 3, batch 30, loss = 2.865583896636963\n",
      "epoch 3, batch 40, loss = 2.8376455307006836\n",
      "epoch 3, batch 50, loss = 2.8753461837768555\n",
      "epoch 3, batch 60, loss = 2.8447930812835693\n",
      "epoch 3, batch 70, loss = 2.8424482345581055\n",
      "epoch 3, batch 80, loss = 2.8661489486694336\n",
      "epoch 3, batch 90, loss = 2.8991518020629883\n",
      "epoch 3, batch 100, loss = 2.793917179107666\n",
      "epoch 3, batch 110, loss = 2.9227371215820312\n",
      "epoch 3, batch 120, loss = 2.8573548793792725\n",
      "epoch 3, batch 130, loss = 2.8338451385498047\n",
      "epoch 3, batch 140, loss = 2.8855626583099365\n",
      "epoch 3, batch 150, loss = 2.840939998626709\n",
      "epoch 3, batch 160, loss = 2.8683390617370605\n",
      "epoch 3, batch 170, loss = 2.8404555320739746\n",
      "epoch 3, batch 180, loss = 2.8266096115112305\n",
      "epoch 3, batch 190, loss = 2.829855442047119\n",
      "epoch 3, batch 200, loss = 2.8039417266845703\n",
      "epoch 3, batch 210, loss = 2.8648557662963867\n",
      "epoch 3, batch 220, loss = 2.864051580429077\n",
      "epoch 3, batch 230, loss = 2.8475234508514404\n",
      "epoch 3, batch 240, loss = 2.8403258323669434\n",
      "epoch 3, batch 250, loss = 2.863309383392334\n",
      "epoch 3, batch 260, loss = 2.839021921157837\n",
      "epoch 3, batch 270, loss = 2.8720197677612305\n",
      "epoch 3, batch 280, loss = 2.859844207763672\n",
      "epoch 4, batch 0, loss = 2.815730571746826\n",
      "epoch 4, batch 10, loss = 2.781728744506836\n",
      "epoch 4, batch 20, loss = 2.8545775413513184\n",
      "epoch 4, batch 30, loss = 2.8893625736236572\n",
      "epoch 4, batch 40, loss = 2.866770029067993\n",
      "epoch 4, batch 50, loss = 2.8102402687072754\n",
      "epoch 4, batch 60, loss = 2.803576946258545\n",
      "epoch 4, batch 70, loss = 2.8470680713653564\n",
      "epoch 4, batch 80, loss = 2.8155219554901123\n",
      "epoch 4, batch 90, loss = 2.7999484539031982\n",
      "epoch 4, batch 100, loss = 2.808084011077881\n",
      "epoch 4, batch 110, loss = 2.868375301361084\n",
      "epoch 4, batch 120, loss = 2.820634365081787\n",
      "epoch 4, batch 130, loss = 2.8292250633239746\n",
      "epoch 4, batch 140, loss = 2.8334057331085205\n",
      "epoch 4, batch 150, loss = 2.838214635848999\n",
      "epoch 4, batch 160, loss = 2.8870058059692383\n",
      "epoch 4, batch 170, loss = 2.81607723236084\n",
      "epoch 4, batch 180, loss = 2.838153123855591\n",
      "epoch 4, batch 190, loss = 2.800154685974121\n",
      "epoch 4, batch 200, loss = 2.8107211589813232\n",
      "epoch 4, batch 210, loss = 2.81428599357605\n",
      "epoch 4, batch 220, loss = 2.854590654373169\n",
      "epoch 4, batch 230, loss = 2.8182291984558105\n",
      "epoch 4, batch 240, loss = 2.802976131439209\n",
      "epoch 4, batch 250, loss = 2.8275060653686523\n",
      "epoch 4, batch 260, loss = 2.842069387435913\n",
      "epoch 4, batch 270, loss = 2.8057608604431152\n",
      "epoch 4, batch 280, loss = 2.819969654083252\n",
      "epoch 5, batch 0, loss = 2.867824077606201\n",
      "epoch 5, batch 10, loss = 2.803243637084961\n",
      "epoch 5, batch 20, loss = 2.797081470489502\n",
      "epoch 5, batch 30, loss = 2.8169310092926025\n",
      "epoch 5, batch 40, loss = 2.814148426055908\n",
      "epoch 5, batch 50, loss = 2.7935914993286133\n",
      "epoch 5, batch 60, loss = 2.8196067810058594\n",
      "epoch 5, batch 70, loss = 2.859081745147705\n",
      "epoch 5, batch 80, loss = 2.7688910961151123\n",
      "epoch 5, batch 90, loss = 2.786834239959717\n",
      "epoch 5, batch 100, loss = 2.7962427139282227\n",
      "epoch 5, batch 110, loss = 2.808558225631714\n",
      "epoch 5, batch 120, loss = 2.779780387878418\n",
      "epoch 5, batch 130, loss = 2.8128750324249268\n",
      "epoch 5, batch 140, loss = 2.8274195194244385\n",
      "epoch 5, batch 150, loss = 2.822294235229492\n",
      "epoch 5, batch 160, loss = 2.8695693016052246\n",
      "epoch 5, batch 170, loss = 2.7687981128692627\n",
      "epoch 5, batch 180, loss = 2.805368423461914\n",
      "epoch 5, batch 190, loss = 2.8410980701446533\n",
      "epoch 5, batch 200, loss = 2.844296455383301\n",
      "epoch 5, batch 210, loss = 2.7592132091522217\n",
      "epoch 5, batch 220, loss = 2.784156322479248\n",
      "epoch 5, batch 230, loss = 2.8253917694091797\n",
      "epoch 5, batch 240, loss = 2.8353750705718994\n",
      "epoch 5, batch 250, loss = 2.8046250343322754\n",
      "epoch 5, batch 260, loss = 2.802243709564209\n",
      "epoch 5, batch 270, loss = 2.864734649658203\n",
      "epoch 5, batch 280, loss = 2.835510492324829\n",
      "epoch 6, batch 0, loss = 2.8396058082580566\n",
      "epoch 6, batch 10, loss = 2.8233017921447754\n",
      "epoch 6, batch 20, loss = 2.798377513885498\n",
      "epoch 6, batch 30, loss = 2.8228087425231934\n",
      "epoch 6, batch 40, loss = 2.819044351577759\n",
      "epoch 6, batch 50, loss = 2.763705015182495\n",
      "epoch 6, batch 60, loss = 2.805002450942993\n",
      "epoch 6, batch 70, loss = 2.7810568809509277\n",
      "epoch 6, batch 80, loss = 2.7661070823669434\n",
      "epoch 6, batch 90, loss = 2.8341822624206543\n",
      "epoch 6, batch 100, loss = 2.799459934234619\n",
      "epoch 6, batch 110, loss = 2.739640712738037\n",
      "epoch 6, batch 120, loss = 2.824437379837036\n",
      "epoch 6, batch 130, loss = 2.8224313259124756\n",
      "epoch 6, batch 140, loss = 2.8103280067443848\n",
      "epoch 6, batch 150, loss = 2.8271496295928955\n",
      "epoch 6, batch 160, loss = 2.825214385986328\n",
      "epoch 6, batch 170, loss = 2.8495800495147705\n",
      "epoch 6, batch 180, loss = 2.778831958770752\n",
      "epoch 6, batch 190, loss = 2.780830144882202\n",
      "epoch 6, batch 200, loss = 2.821824789047241\n",
      "epoch 6, batch 210, loss = 2.8896448612213135\n",
      "epoch 6, batch 220, loss = 2.803208827972412\n",
      "epoch 6, batch 230, loss = 2.8402671813964844\n",
      "epoch 6, batch 240, loss = 2.7681005001068115\n",
      "epoch 6, batch 250, loss = 2.7925009727478027\n",
      "epoch 6, batch 260, loss = 2.82576322555542\n",
      "epoch 6, batch 270, loss = 2.802603244781494\n",
      "epoch 6, batch 280, loss = 2.7886290550231934\n",
      "epoch 7, batch 0, loss = 2.815364122390747\n",
      "epoch 7, batch 10, loss = 2.7987990379333496\n",
      "epoch 7, batch 20, loss = 2.76107120513916\n",
      "epoch 7, batch 30, loss = 2.7781829833984375\n",
      "epoch 7, batch 40, loss = 2.7991490364074707\n",
      "epoch 7, batch 50, loss = 2.7632617950439453\n",
      "epoch 7, batch 60, loss = 2.7731876373291016\n",
      "epoch 7, batch 70, loss = 2.7604637145996094\n",
      "epoch 7, batch 80, loss = 2.835538864135742\n",
      "epoch 7, batch 90, loss = 2.789417028427124\n",
      "epoch 7, batch 100, loss = 2.7992944717407227\n",
      "epoch 7, batch 110, loss = 2.800215244293213\n",
      "epoch 7, batch 120, loss = 2.818324565887451\n",
      "epoch 7, batch 130, loss = 2.815006732940674\n",
      "epoch 7, batch 140, loss = 2.770108222961426\n",
      "epoch 7, batch 150, loss = 2.814157009124756\n",
      "epoch 7, batch 160, loss = 2.815775156021118\n",
      "epoch 7, batch 170, loss = 2.766360282897949\n",
      "epoch 7, batch 180, loss = 2.7925281524658203\n",
      "epoch 7, batch 190, loss = 2.774510383605957\n",
      "epoch 7, batch 200, loss = 2.7816812992095947\n",
      "epoch 7, batch 210, loss = 2.8446435928344727\n",
      "epoch 7, batch 220, loss = 2.7866134643554688\n",
      "epoch 7, batch 230, loss = 2.870253086090088\n",
      "epoch 7, batch 240, loss = 2.822429656982422\n",
      "epoch 7, batch 250, loss = 2.7607147693634033\n",
      "epoch 7, batch 260, loss = 2.766543388366699\n",
      "epoch 7, batch 270, loss = 2.799213409423828\n",
      "epoch 7, batch 280, loss = 2.836422920227051\n",
      "epoch 8, batch 0, loss = 2.839156150817871\n",
      "epoch 8, batch 10, loss = 2.7868456840515137\n",
      "epoch 8, batch 20, loss = 2.8176941871643066\n",
      "epoch 8, batch 30, loss = 2.776733875274658\n",
      "epoch 8, batch 40, loss = 2.792797088623047\n",
      "epoch 8, batch 50, loss = 2.750633716583252\n",
      "epoch 8, batch 60, loss = 2.8195571899414062\n",
      "epoch 8, batch 70, loss = 2.7619128227233887\n",
      "epoch 8, batch 80, loss = 2.7520580291748047\n",
      "epoch 8, batch 90, loss = 2.7816197872161865\n",
      "epoch 8, batch 100, loss = 2.792023181915283\n",
      "epoch 8, batch 110, loss = 2.776433229446411\n",
      "epoch 8, batch 120, loss = 2.7747321128845215\n",
      "epoch 8, batch 130, loss = 2.776451587677002\n",
      "epoch 8, batch 140, loss = 2.835505485534668\n",
      "epoch 8, batch 150, loss = 2.818861246109009\n",
      "epoch 8, batch 160, loss = 2.8472466468811035\n",
      "epoch 8, batch 170, loss = 2.8233091831207275\n",
      "epoch 8, batch 180, loss = 2.7875633239746094\n",
      "epoch 8, batch 190, loss = 2.7909939289093018\n",
      "epoch 8, batch 200, loss = 2.808317184448242\n",
      "epoch 8, batch 210, loss = 2.772104263305664\n",
      "epoch 8, batch 220, loss = 2.8270418643951416\n",
      "epoch 8, batch 230, loss = 2.7464284896850586\n",
      "epoch 8, batch 240, loss = 2.7965216636657715\n",
      "epoch 8, batch 250, loss = 2.8044958114624023\n",
      "epoch 8, batch 260, loss = 2.7919938564300537\n",
      "epoch 8, batch 270, loss = 2.7089240550994873\n",
      "epoch 8, batch 280, loss = 2.811998128890991\n",
      "epoch 9, batch 0, loss = 2.8265271186828613\n",
      "epoch 9, batch 10, loss = 2.7795121669769287\n",
      "epoch 9, batch 20, loss = 2.753308057785034\n",
      "epoch 9, batch 30, loss = 2.75852632522583\n",
      "epoch 9, batch 40, loss = 2.7890970706939697\n",
      "epoch 9, batch 50, loss = 2.8016114234924316\n",
      "epoch 9, batch 60, loss = 2.755269765853882\n",
      "epoch 9, batch 70, loss = 2.737586498260498\n",
      "epoch 9, batch 80, loss = 2.7407402992248535\n",
      "epoch 9, batch 90, loss = 2.830080032348633\n",
      "epoch 9, batch 100, loss = 2.7931325435638428\n",
      "epoch 9, batch 110, loss = 2.7671561241149902\n",
      "epoch 9, batch 120, loss = 2.743522882461548\n",
      "epoch 9, batch 130, loss = 2.7815542221069336\n",
      "epoch 9, batch 140, loss = 2.7449707984924316\n",
      "epoch 9, batch 150, loss = 2.8498706817626953\n",
      "epoch 9, batch 160, loss = 2.7858197689056396\n",
      "epoch 9, batch 170, loss = 2.770878791809082\n",
      "epoch 9, batch 180, loss = 2.7426209449768066\n",
      "epoch 9, batch 190, loss = 2.7826242446899414\n",
      "epoch 9, batch 200, loss = 2.8117623329162598\n",
      "epoch 9, batch 210, loss = 2.816380500793457\n",
      "epoch 9, batch 220, loss = 2.8072750568389893\n",
      "epoch 9, batch 230, loss = 2.815078020095825\n",
      "epoch 9, batch 240, loss = 2.6901113986968994\n",
      "epoch 9, batch 250, loss = 2.7808446884155273\n",
      "epoch 9, batch 260, loss = 2.804286241531372\n",
      "epoch 9, batch 270, loss = 2.781397819519043\n",
      "epoch 9, batch 280, loss = 2.7858099937438965\n",
      "epoch 10, batch 0, loss = 2.7948720455169678\n",
      "epoch 10, batch 10, loss = 2.7462358474731445\n",
      "epoch 10, batch 20, loss = 2.7588682174682617\n",
      "epoch 10, batch 30, loss = 2.751741647720337\n",
      "epoch 10, batch 40, loss = 2.7370405197143555\n",
      "epoch 10, batch 50, loss = 2.7273201942443848\n",
      "epoch 10, batch 60, loss = 2.7564697265625\n",
      "epoch 10, batch 70, loss = 2.7266454696655273\n",
      "epoch 10, batch 80, loss = 2.707296371459961\n",
      "epoch 10, batch 90, loss = 2.8270983695983887\n",
      "epoch 10, batch 100, loss = 2.8137571811676025\n",
      "epoch 10, batch 110, loss = 2.742433547973633\n",
      "epoch 10, batch 120, loss = 2.8187763690948486\n",
      "epoch 10, batch 130, loss = 2.7771432399749756\n",
      "epoch 10, batch 140, loss = 2.7536022663116455\n",
      "epoch 10, batch 150, loss = 2.7858164310455322\n",
      "epoch 10, batch 160, loss = 2.774899959564209\n",
      "epoch 10, batch 170, loss = 2.8119900226593018\n",
      "epoch 10, batch 180, loss = 2.7541699409484863\n",
      "epoch 10, batch 190, loss = 2.7600321769714355\n",
      "epoch 10, batch 200, loss = 2.7660951614379883\n",
      "epoch 10, batch 210, loss = 2.780625820159912\n",
      "epoch 10, batch 220, loss = 2.7415549755096436\n",
      "epoch 10, batch 230, loss = 2.7585363388061523\n",
      "epoch 10, batch 240, loss = 2.8059098720550537\n",
      "epoch 10, batch 250, loss = 2.797344207763672\n",
      "epoch 10, batch 260, loss = 2.7824933528900146\n",
      "epoch 10, batch 270, loss = 2.749959945678711\n",
      "epoch 10, batch 280, loss = 2.81402587890625\n",
      "epoch 11, batch 0, loss = 2.7465720176696777\n",
      "epoch 11, batch 10, loss = 2.738797426223755\n",
      "epoch 11, batch 20, loss = 2.8229668140411377\n",
      "epoch 11, batch 30, loss = 2.784090995788574\n",
      "epoch 11, batch 40, loss = 2.8164730072021484\n",
      "epoch 11, batch 50, loss = 2.7472519874572754\n",
      "epoch 11, batch 60, loss = 2.7313692569732666\n",
      "epoch 11, batch 70, loss = 2.770782470703125\n",
      "epoch 11, batch 80, loss = 2.80888032913208\n",
      "epoch 11, batch 90, loss = 2.7781715393066406\n",
      "epoch 11, batch 100, loss = 2.7252960205078125\n",
      "epoch 11, batch 110, loss = 2.76285457611084\n",
      "epoch 11, batch 120, loss = 2.7744290828704834\n",
      "epoch 11, batch 130, loss = 2.775097370147705\n",
      "epoch 11, batch 140, loss = 2.7806406021118164\n",
      "epoch 11, batch 150, loss = 2.7759761810302734\n",
      "epoch 11, batch 160, loss = 2.755457639694214\n",
      "epoch 11, batch 170, loss = 2.6992225646972656\n",
      "epoch 11, batch 180, loss = 2.755645990371704\n",
      "epoch 11, batch 190, loss = 2.7162599563598633\n",
      "epoch 11, batch 200, loss = 2.7259511947631836\n",
      "epoch 11, batch 210, loss = 2.771799325942993\n",
      "epoch 11, batch 220, loss = 2.7975687980651855\n",
      "epoch 11, batch 230, loss = 2.7549521923065186\n",
      "epoch 11, batch 240, loss = 2.772054672241211\n",
      "epoch 11, batch 250, loss = 2.718790292739868\n",
      "epoch 11, batch 260, loss = 2.7623419761657715\n",
      "epoch 11, batch 270, loss = 2.6957743167877197\n",
      "epoch 11, batch 280, loss = 2.743338108062744\n",
      "epoch 12, batch 0, loss = 2.7436070442199707\n",
      "epoch 12, batch 10, loss = 2.7250990867614746\n",
      "epoch 12, batch 20, loss = 2.7504220008850098\n",
      "epoch 12, batch 30, loss = 2.761115074157715\n",
      "epoch 12, batch 40, loss = 2.760080337524414\n",
      "epoch 12, batch 50, loss = 2.7933313846588135\n",
      "epoch 12, batch 60, loss = 2.736818313598633\n",
      "epoch 12, batch 70, loss = 2.8018717765808105\n",
      "epoch 12, batch 80, loss = 2.7957706451416016\n",
      "epoch 12, batch 90, loss = 2.771106719970703\n",
      "epoch 12, batch 100, loss = 2.719494342803955\n",
      "epoch 12, batch 110, loss = 2.754232883453369\n",
      "epoch 12, batch 120, loss = 2.7268383502960205\n",
      "epoch 12, batch 130, loss = 2.788606643676758\n",
      "epoch 12, batch 140, loss = 2.8101367950439453\n",
      "epoch 12, batch 150, loss = 2.7805426120758057\n",
      "epoch 12, batch 160, loss = 2.7684245109558105\n",
      "epoch 12, batch 170, loss = 2.790194034576416\n",
      "epoch 12, batch 180, loss = 2.7479958534240723\n",
      "epoch 12, batch 190, loss = 2.8000571727752686\n",
      "epoch 12, batch 200, loss = 2.777552604675293\n",
      "epoch 12, batch 210, loss = 2.7564620971679688\n",
      "epoch 12, batch 220, loss = 2.748940944671631\n",
      "epoch 12, batch 230, loss = 2.7891082763671875\n",
      "epoch 12, batch 240, loss = 2.7095439434051514\n",
      "epoch 12, batch 250, loss = 2.7231545448303223\n",
      "epoch 12, batch 260, loss = 2.7544326782226562\n",
      "epoch 12, batch 270, loss = 2.7639970779418945\n",
      "epoch 12, batch 280, loss = 2.7820076942443848\n",
      "epoch 13, batch 0, loss = 2.7432427406311035\n",
      "epoch 13, batch 10, loss = 2.6946465969085693\n",
      "epoch 13, batch 20, loss = 2.7384560108184814\n",
      "epoch 13, batch 30, loss = 2.7634377479553223\n",
      "epoch 13, batch 40, loss = 2.7390506267547607\n",
      "epoch 13, batch 50, loss = 2.7300281524658203\n",
      "epoch 13, batch 60, loss = 2.7479517459869385\n",
      "epoch 13, batch 70, loss = 2.7276525497436523\n",
      "epoch 13, batch 80, loss = 2.7763850688934326\n",
      "epoch 13, batch 90, loss = 2.720278263092041\n",
      "epoch 13, batch 100, loss = 2.748816967010498\n",
      "epoch 13, batch 110, loss = 2.7555465698242188\n",
      "epoch 13, batch 120, loss = 2.743793487548828\n",
      "epoch 13, batch 130, loss = 2.8007655143737793\n",
      "epoch 13, batch 140, loss = 2.8121185302734375\n",
      "epoch 13, batch 150, loss = 2.795393466949463\n",
      "epoch 13, batch 160, loss = 2.739061117172241\n",
      "epoch 13, batch 170, loss = 2.783433198928833\n",
      "epoch 13, batch 180, loss = 2.7571048736572266\n",
      "epoch 13, batch 190, loss = 2.757528781890869\n",
      "epoch 13, batch 200, loss = 2.7678146362304688\n",
      "epoch 13, batch 210, loss = 2.752199649810791\n",
      "epoch 13, batch 220, loss = 2.751049041748047\n",
      "epoch 13, batch 230, loss = 2.7264461517333984\n",
      "epoch 13, batch 240, loss = 2.7565202713012695\n",
      "epoch 13, batch 250, loss = 2.7629661560058594\n",
      "epoch 13, batch 260, loss = 2.747809410095215\n",
      "epoch 13, batch 270, loss = 2.784426689147949\n",
      "epoch 13, batch 280, loss = 2.824671506881714\n",
      "epoch 14, batch 0, loss = 2.733717441558838\n",
      "epoch 14, batch 10, loss = 2.720203399658203\n",
      "epoch 14, batch 20, loss = 2.8235440254211426\n",
      "epoch 14, batch 30, loss = 2.7451224327087402\n",
      "epoch 14, batch 40, loss = 2.742399215698242\n",
      "epoch 14, batch 50, loss = 2.776416540145874\n",
      "epoch 14, batch 60, loss = 2.7874748706817627\n",
      "epoch 14, batch 70, loss = 2.7537331581115723\n",
      "epoch 14, batch 80, loss = 2.754495143890381\n",
      "epoch 14, batch 90, loss = 2.7250468730926514\n",
      "epoch 14, batch 100, loss = 2.787221908569336\n",
      "epoch 14, batch 110, loss = 2.779923677444458\n",
      "epoch 14, batch 120, loss = 2.743305206298828\n",
      "epoch 14, batch 130, loss = 2.742003917694092\n",
      "epoch 14, batch 140, loss = 2.7607462406158447\n",
      "epoch 14, batch 150, loss = 2.7137298583984375\n",
      "epoch 14, batch 160, loss = 2.690117597579956\n",
      "epoch 14, batch 170, loss = 2.7719688415527344\n",
      "epoch 14, batch 180, loss = 2.7834651470184326\n",
      "epoch 14, batch 190, loss = 2.751099109649658\n",
      "epoch 14, batch 200, loss = 2.745469808578491\n",
      "epoch 14, batch 210, loss = 2.7794904708862305\n",
      "epoch 14, batch 220, loss = 2.7208399772644043\n",
      "epoch 14, batch 230, loss = 2.7605860233306885\n",
      "epoch 14, batch 240, loss = 2.740964889526367\n",
      "epoch 14, batch 250, loss = 2.745680093765259\n",
      "epoch 14, batch 260, loss = 2.732501268386841\n",
      "epoch 14, batch 270, loss = 2.805452823638916\n",
      "epoch 14, batch 280, loss = 2.7612576484680176\n",
      "epoch 15, batch 0, loss = 2.749985694885254\n",
      "epoch 15, batch 10, loss = 2.7472550868988037\n",
      "epoch 15, batch 20, loss = 2.768324851989746\n",
      "epoch 15, batch 30, loss = 2.7761001586914062\n",
      "epoch 15, batch 40, loss = 2.7041501998901367\n",
      "epoch 15, batch 50, loss = 2.741759777069092\n",
      "epoch 15, batch 60, loss = 2.702907085418701\n",
      "epoch 15, batch 70, loss = 2.759387969970703\n",
      "epoch 15, batch 80, loss = 2.783720016479492\n",
      "epoch 15, batch 90, loss = 2.7384443283081055\n",
      "epoch 15, batch 100, loss = 2.7458877563476562\n",
      "epoch 15, batch 110, loss = 2.684483766555786\n",
      "epoch 15, batch 120, loss = 2.8241689205169678\n",
      "epoch 15, batch 130, loss = 2.7222282886505127\n",
      "epoch 15, batch 140, loss = 2.7515506744384766\n",
      "epoch 15, batch 150, loss = 2.6962461471557617\n",
      "epoch 15, batch 160, loss = 2.708956480026245\n",
      "epoch 15, batch 170, loss = 2.774134874343872\n",
      "epoch 15, batch 180, loss = 2.7769484519958496\n",
      "epoch 15, batch 190, loss = 2.7111096382141113\n",
      "epoch 15, batch 200, loss = 2.769374370574951\n",
      "epoch 15, batch 210, loss = 2.7767927646636963\n",
      "epoch 15, batch 220, loss = 2.821810722351074\n",
      "epoch 15, batch 230, loss = 2.755030393600464\n",
      "epoch 15, batch 240, loss = 2.7409720420837402\n",
      "epoch 15, batch 250, loss = 2.686936378479004\n",
      "epoch 15, batch 260, loss = 2.7359135150909424\n",
      "epoch 15, batch 270, loss = 2.774707078933716\n",
      "epoch 15, batch 280, loss = 2.7785754203796387\n",
      "epoch 16, batch 0, loss = 2.705501079559326\n",
      "epoch 16, batch 10, loss = 2.7223968505859375\n",
      "epoch 16, batch 20, loss = 2.71293306350708\n",
      "epoch 16, batch 30, loss = 2.7655131816864014\n",
      "epoch 16, batch 40, loss = 2.7365400791168213\n",
      "epoch 16, batch 50, loss = 2.7311697006225586\n",
      "epoch 16, batch 60, loss = 2.783597946166992\n",
      "epoch 16, batch 70, loss = 2.7896857261657715\n",
      "epoch 16, batch 80, loss = 2.7412781715393066\n",
      "epoch 16, batch 90, loss = 2.742586374282837\n",
      "epoch 16, batch 100, loss = 2.7653965950012207\n",
      "epoch 16, batch 110, loss = 2.7547645568847656\n",
      "epoch 16, batch 120, loss = 2.799912929534912\n",
      "epoch 16, batch 130, loss = 2.7487382888793945\n",
      "epoch 16, batch 140, loss = 2.7535791397094727\n",
      "epoch 16, batch 150, loss = 2.7346580028533936\n",
      "epoch 16, batch 160, loss = 2.7191343307495117\n",
      "epoch 16, batch 170, loss = 2.827687978744507\n",
      "epoch 16, batch 180, loss = 2.7387146949768066\n",
      "epoch 16, batch 190, loss = 2.735372543334961\n",
      "epoch 16, batch 200, loss = 2.763367176055908\n",
      "epoch 16, batch 210, loss = 2.7474217414855957\n",
      "epoch 16, batch 220, loss = 2.7423477172851562\n",
      "epoch 16, batch 230, loss = 2.7836124897003174\n",
      "epoch 16, batch 240, loss = 2.771005630493164\n",
      "epoch 16, batch 250, loss = 2.7206478118896484\n",
      "epoch 16, batch 260, loss = 2.767550468444824\n",
      "epoch 16, batch 270, loss = 2.7124550342559814\n",
      "epoch 16, batch 280, loss = 2.7173149585723877\n",
      "epoch 17, batch 0, loss = 2.7192912101745605\n",
      "epoch 17, batch 10, loss = 2.7498154640197754\n",
      "epoch 17, batch 20, loss = 2.709920644760132\n",
      "epoch 17, batch 30, loss = 2.7865185737609863\n",
      "epoch 17, batch 40, loss = 2.7183847427368164\n",
      "epoch 17, batch 50, loss = 2.7172629833221436\n",
      "epoch 17, batch 60, loss = 2.72011661529541\n",
      "epoch 17, batch 70, loss = 2.708031177520752\n",
      "epoch 17, batch 80, loss = 2.7933130264282227\n",
      "epoch 17, batch 90, loss = 2.7624614238739014\n",
      "epoch 17, batch 100, loss = 2.6917872428894043\n",
      "epoch 17, batch 110, loss = 2.805863380432129\n",
      "epoch 17, batch 120, loss = 2.7222518920898438\n",
      "epoch 17, batch 130, loss = 2.784975051879883\n",
      "epoch 17, batch 140, loss = 2.727567195892334\n",
      "epoch 17, batch 150, loss = 2.685462474822998\n",
      "epoch 17, batch 160, loss = 2.7719192504882812\n",
      "epoch 17, batch 170, loss = 2.766181468963623\n",
      "epoch 17, batch 180, loss = 2.6857852935791016\n",
      "epoch 17, batch 190, loss = 2.724297046661377\n",
      "epoch 17, batch 200, loss = 2.7194416522979736\n",
      "epoch 17, batch 210, loss = 2.773527145385742\n",
      "epoch 17, batch 220, loss = 2.7390995025634766\n",
      "epoch 17, batch 230, loss = 2.6991193294525146\n",
      "epoch 17, batch 240, loss = 2.7109382152557373\n",
      "epoch 17, batch 250, loss = 2.737468719482422\n",
      "epoch 17, batch 260, loss = 2.770753860473633\n",
      "epoch 17, batch 270, loss = 2.8159475326538086\n",
      "epoch 17, batch 280, loss = 2.7389066219329834\n",
      "epoch 18, batch 0, loss = 2.7342309951782227\n",
      "epoch 18, batch 10, loss = 2.8004069328308105\n",
      "epoch 18, batch 20, loss = 2.7908878326416016\n",
      "epoch 18, batch 30, loss = 2.779419422149658\n",
      "epoch 18, batch 40, loss = 2.7063241004943848\n",
      "epoch 18, batch 50, loss = 2.7254161834716797\n",
      "epoch 18, batch 60, loss = 2.770962953567505\n",
      "epoch 18, batch 70, loss = 2.7413647174835205\n",
      "epoch 18, batch 80, loss = 2.700768232345581\n",
      "epoch 18, batch 90, loss = 2.7285213470458984\n",
      "epoch 18, batch 100, loss = 2.8069894313812256\n",
      "epoch 18, batch 110, loss = 2.6835055351257324\n",
      "epoch 18, batch 120, loss = 2.768263578414917\n",
      "epoch 18, batch 130, loss = 2.7109227180480957\n",
      "epoch 18, batch 140, loss = 2.7651848793029785\n",
      "epoch 18, batch 150, loss = 2.7777042388916016\n",
      "epoch 18, batch 160, loss = 2.6918153762817383\n",
      "epoch 18, batch 170, loss = 2.7123796939849854\n",
      "epoch 18, batch 180, loss = 2.7561113834381104\n",
      "epoch 18, batch 190, loss = 2.739978313446045\n",
      "epoch 18, batch 200, loss = 2.7590079307556152\n",
      "epoch 18, batch 210, loss = 2.730628252029419\n",
      "epoch 18, batch 220, loss = 2.7350425720214844\n",
      "epoch 18, batch 230, loss = 2.799804210662842\n",
      "epoch 18, batch 240, loss = 2.7901573181152344\n",
      "epoch 18, batch 250, loss = 2.7220401763916016\n",
      "epoch 18, batch 260, loss = 2.720398426055908\n",
      "epoch 18, batch 270, loss = 2.745573043823242\n",
      "epoch 18, batch 280, loss = 2.7107040882110596\n",
      "epoch 19, batch 0, loss = 2.7685277462005615\n",
      "epoch 19, batch 10, loss = 2.690217971801758\n",
      "epoch 19, batch 20, loss = 2.7097105979919434\n",
      "epoch 19, batch 30, loss = 2.724656581878662\n",
      "epoch 19, batch 40, loss = 2.7231249809265137\n",
      "epoch 19, batch 50, loss = 2.720536947250366\n",
      "epoch 19, batch 60, loss = 2.740734100341797\n",
      "epoch 19, batch 70, loss = 2.750764846801758\n",
      "epoch 19, batch 80, loss = 2.713139533996582\n",
      "epoch 19, batch 90, loss = 2.7580924034118652\n",
      "epoch 19, batch 100, loss = 2.7067930698394775\n",
      "epoch 19, batch 110, loss = 2.7530765533447266\n",
      "epoch 19, batch 120, loss = 2.6966426372528076\n",
      "epoch 19, batch 130, loss = 2.6913914680480957\n",
      "epoch 19, batch 140, loss = 2.6795783042907715\n",
      "epoch 19, batch 150, loss = 2.736107349395752\n",
      "epoch 19, batch 160, loss = 2.7206482887268066\n",
      "epoch 19, batch 170, loss = 2.7453970909118652\n",
      "epoch 19, batch 180, loss = 2.677737236022949\n",
      "epoch 19, batch 190, loss = 2.708773136138916\n",
      "epoch 19, batch 200, loss = 2.7892441749572754\n",
      "epoch 19, batch 210, loss = 2.712859869003296\n",
      "epoch 19, batch 220, loss = 2.751162052154541\n",
      "epoch 19, batch 230, loss = 2.696547269821167\n",
      "epoch 19, batch 240, loss = 2.751220464706421\n",
      "epoch 19, batch 250, loss = 2.6746582984924316\n",
      "epoch 19, batch 260, loss = 2.744894504547119\n",
      "epoch 19, batch 270, loss = 2.727487087249756\n",
      "epoch 19, batch 280, loss = 2.664360523223877\n",
      "epoch 20, batch 0, loss = 2.789520502090454\n",
      "epoch 20, batch 10, loss = 2.731605291366577\n",
      "epoch 20, batch 20, loss = 2.6921441555023193\n",
      "epoch 20, batch 30, loss = 2.727252960205078\n",
      "epoch 20, batch 40, loss = 2.7040390968322754\n",
      "epoch 20, batch 50, loss = 2.729862689971924\n",
      "epoch 20, batch 60, loss = 2.7062997817993164\n",
      "epoch 20, batch 70, loss = 2.699798345565796\n",
      "epoch 20, batch 80, loss = 2.716851234436035\n",
      "epoch 20, batch 90, loss = 2.742673873901367\n",
      "epoch 20, batch 100, loss = 2.7461061477661133\n",
      "epoch 20, batch 110, loss = 2.7775349617004395\n",
      "epoch 20, batch 120, loss = 2.722916603088379\n",
      "epoch 20, batch 130, loss = 2.7185473442077637\n",
      "epoch 20, batch 140, loss = 2.6924915313720703\n",
      "epoch 20, batch 150, loss = 2.757173538208008\n",
      "epoch 20, batch 160, loss = 2.687765598297119\n",
      "epoch 20, batch 170, loss = 2.7252449989318848\n",
      "epoch 20, batch 180, loss = 2.7552480697631836\n",
      "epoch 20, batch 190, loss = 2.7638235092163086\n",
      "epoch 20, batch 200, loss = 2.681053400039673\n",
      "epoch 20, batch 210, loss = 2.791900396347046\n",
      "epoch 20, batch 220, loss = 2.715935230255127\n",
      "epoch 20, batch 230, loss = 2.711535930633545\n",
      "epoch 20, batch 240, loss = 2.7422943115234375\n",
      "epoch 20, batch 250, loss = 2.8083584308624268\n",
      "epoch 20, batch 260, loss = 2.6831891536712646\n",
      "epoch 20, batch 270, loss = 2.740598678588867\n",
      "epoch 20, batch 280, loss = 2.7210538387298584\n",
      "epoch 21, batch 0, loss = 2.6692514419555664\n",
      "epoch 21, batch 10, loss = 2.745333194732666\n",
      "epoch 21, batch 20, loss = 2.722679615020752\n",
      "epoch 21, batch 30, loss = 2.645475149154663\n",
      "epoch 21, batch 40, loss = 2.7496721744537354\n",
      "epoch 21, batch 50, loss = 2.7032723426818848\n",
      "epoch 21, batch 60, loss = 2.6701292991638184\n",
      "epoch 21, batch 70, loss = 2.673983097076416\n",
      "epoch 21, batch 80, loss = 2.70261812210083\n",
      "epoch 21, batch 90, loss = 2.7100014686584473\n",
      "epoch 21, batch 100, loss = 2.7042524814605713\n",
      "epoch 21, batch 110, loss = 2.6955277919769287\n",
      "epoch 21, batch 120, loss = 2.7066688537597656\n",
      "epoch 21, batch 130, loss = 2.703913688659668\n",
      "epoch 21, batch 140, loss = 2.708799362182617\n",
      "epoch 21, batch 150, loss = 2.7480461597442627\n",
      "epoch 21, batch 160, loss = 2.703803062438965\n",
      "epoch 21, batch 170, loss = 2.6833600997924805\n",
      "epoch 21, batch 180, loss = 2.721717596054077\n",
      "epoch 21, batch 190, loss = 2.700941801071167\n",
      "epoch 21, batch 200, loss = 2.788100242614746\n",
      "epoch 21, batch 210, loss = 2.7199547290802\n",
      "epoch 21, batch 220, loss = 2.7330217361450195\n",
      "epoch 21, batch 230, loss = 2.7052955627441406\n",
      "epoch 21, batch 240, loss = 2.7389535903930664\n",
      "epoch 21, batch 250, loss = 2.7243809700012207\n",
      "epoch 21, batch 260, loss = 2.767573833465576\n",
      "epoch 21, batch 270, loss = 2.6809492111206055\n",
      "epoch 21, batch 280, loss = 2.7877559661865234\n",
      "epoch 22, batch 0, loss = 2.7180581092834473\n",
      "epoch 22, batch 10, loss = 2.737823009490967\n",
      "epoch 22, batch 20, loss = 2.7262916564941406\n",
      "epoch 22, batch 30, loss = 2.7088122367858887\n",
      "epoch 22, batch 40, loss = 2.7035646438598633\n",
      "epoch 22, batch 50, loss = 2.675342559814453\n",
      "epoch 22, batch 60, loss = 2.6848506927490234\n",
      "epoch 22, batch 70, loss = 2.6811110973358154\n",
      "epoch 22, batch 80, loss = 2.7486701011657715\n",
      "epoch 22, batch 90, loss = 2.7636046409606934\n",
      "epoch 22, batch 100, loss = 2.7474350929260254\n",
      "epoch 22, batch 110, loss = 2.7522788047790527\n",
      "epoch 22, batch 120, loss = 2.6984825134277344\n",
      "epoch 22, batch 130, loss = 2.658881187438965\n",
      "epoch 22, batch 140, loss = 2.7134804725646973\n",
      "epoch 22, batch 150, loss = 2.727280616760254\n",
      "epoch 22, batch 160, loss = 2.6872987747192383\n",
      "epoch 22, batch 170, loss = 2.724303722381592\n",
      "epoch 22, batch 180, loss = 2.736478328704834\n",
      "epoch 22, batch 190, loss = 2.7040491104125977\n",
      "epoch 22, batch 200, loss = 2.6718103885650635\n",
      "epoch 22, batch 210, loss = 2.742438554763794\n",
      "epoch 22, batch 220, loss = 2.703874349594116\n",
      "epoch 22, batch 230, loss = 2.72981595993042\n",
      "epoch 22, batch 240, loss = 2.7497146129608154\n",
      "epoch 22, batch 250, loss = 2.775857925415039\n",
      "epoch 22, batch 260, loss = 2.724395751953125\n",
      "epoch 22, batch 270, loss = 2.7531778812408447\n",
      "epoch 22, batch 280, loss = 2.6471123695373535\n",
      "epoch 23, batch 0, loss = 2.640352725982666\n",
      "epoch 23, batch 10, loss = 2.7512450218200684\n",
      "epoch 23, batch 20, loss = 2.7180659770965576\n",
      "epoch 23, batch 30, loss = 2.661557197570801\n",
      "epoch 23, batch 40, loss = 2.738577365875244\n",
      "epoch 23, batch 50, loss = 2.6474783420562744\n",
      "epoch 23, batch 60, loss = 2.6853761672973633\n",
      "epoch 23, batch 70, loss = 2.6941566467285156\n",
      "epoch 23, batch 80, loss = 2.7202703952789307\n",
      "epoch 23, batch 90, loss = 2.6867125034332275\n",
      "epoch 23, batch 100, loss = 2.6570544242858887\n",
      "epoch 23, batch 110, loss = 2.7000010013580322\n",
      "epoch 23, batch 120, loss = 2.7376656532287598\n",
      "epoch 23, batch 130, loss = 2.7129135131835938\n",
      "epoch 23, batch 140, loss = 2.6781225204467773\n",
      "epoch 23, batch 150, loss = 2.704421043395996\n",
      "epoch 23, batch 160, loss = 2.7388854026794434\n",
      "epoch 23, batch 170, loss = 2.701704978942871\n",
      "epoch 23, batch 180, loss = 2.724807024002075\n",
      "epoch 23, batch 190, loss = 2.6882379055023193\n",
      "epoch 23, batch 200, loss = 2.721832275390625\n",
      "epoch 23, batch 210, loss = 2.7440319061279297\n",
      "epoch 23, batch 220, loss = 2.7008705139160156\n",
      "epoch 23, batch 230, loss = 2.7680678367614746\n",
      "epoch 23, batch 240, loss = 2.6813859939575195\n",
      "epoch 23, batch 250, loss = 2.7205986976623535\n",
      "epoch 23, batch 260, loss = 2.7024354934692383\n",
      "epoch 23, batch 270, loss = 2.726337194442749\n",
      "epoch 23, batch 280, loss = 2.7069296836853027\n",
      "epoch 24, batch 0, loss = 2.696549654006958\n",
      "epoch 24, batch 10, loss = 2.757750988006592\n",
      "epoch 24, batch 20, loss = 2.6808576583862305\n",
      "epoch 24, batch 30, loss = 2.7280805110931396\n",
      "epoch 24, batch 40, loss = 2.763535261154175\n",
      "epoch 24, batch 50, loss = 2.7386693954467773\n",
      "epoch 24, batch 60, loss = 2.7240164279937744\n",
      "epoch 24, batch 70, loss = 2.6976470947265625\n",
      "epoch 24, batch 80, loss = 2.723006248474121\n",
      "epoch 24, batch 90, loss = 2.650681495666504\n",
      "epoch 24, batch 100, loss = 2.707435369491577\n",
      "epoch 24, batch 110, loss = 2.7198033332824707\n",
      "epoch 24, batch 120, loss = 2.698481559753418\n",
      "epoch 24, batch 130, loss = 2.7110047340393066\n",
      "epoch 24, batch 140, loss = 2.7730913162231445\n",
      "epoch 24, batch 150, loss = 2.726072072982788\n",
      "epoch 24, batch 160, loss = 2.7449488639831543\n",
      "epoch 24, batch 170, loss = 2.7516753673553467\n",
      "epoch 24, batch 180, loss = 2.680227279663086\n",
      "epoch 24, batch 190, loss = 2.7417852878570557\n",
      "epoch 24, batch 200, loss = 2.7077314853668213\n",
      "epoch 24, batch 210, loss = 2.633399248123169\n",
      "epoch 24, batch 220, loss = 2.718834400177002\n",
      "epoch 24, batch 230, loss = 2.7125048637390137\n",
      "epoch 24, batch 240, loss = 2.667387008666992\n",
      "epoch 24, batch 250, loss = 2.7137722969055176\n",
      "epoch 24, batch 260, loss = 2.748802423477173\n",
      "epoch 24, batch 270, loss = 2.718759775161743\n",
      "epoch 24, batch 280, loss = 2.6782002449035645\n",
      "epoch 25, batch 0, loss = 2.697568893432617\n",
      "epoch 25, batch 10, loss = 2.709233283996582\n",
      "epoch 25, batch 20, loss = 2.7163009643554688\n",
      "epoch 25, batch 30, loss = 2.7203855514526367\n",
      "epoch 25, batch 40, loss = 2.687948226928711\n",
      "epoch 25, batch 50, loss = 2.7140426635742188\n",
      "epoch 25, batch 60, loss = 2.6601595878601074\n",
      "epoch 25, batch 70, loss = 2.679180145263672\n",
      "epoch 25, batch 80, loss = 2.731379508972168\n",
      "epoch 25, batch 90, loss = 2.76461124420166\n",
      "epoch 25, batch 100, loss = 2.6919829845428467\n",
      "epoch 25, batch 110, loss = 2.691849708557129\n",
      "epoch 25, batch 120, loss = 2.6903586387634277\n",
      "epoch 25, batch 130, loss = 2.676257371902466\n",
      "epoch 25, batch 140, loss = 2.760714530944824\n",
      "epoch 25, batch 150, loss = 2.746680974960327\n",
      "epoch 25, batch 160, loss = 2.6905531883239746\n",
      "epoch 25, batch 170, loss = 2.6785974502563477\n",
      "epoch 25, batch 180, loss = 2.6685149669647217\n",
      "epoch 25, batch 190, loss = 2.7412405014038086\n",
      "epoch 25, batch 200, loss = 2.713995933532715\n",
      "epoch 25, batch 210, loss = 2.6997361183166504\n",
      "epoch 25, batch 220, loss = 2.6912925243377686\n",
      "epoch 25, batch 230, loss = 2.688183307647705\n",
      "epoch 25, batch 240, loss = 2.691530466079712\n",
      "epoch 25, batch 250, loss = 2.7052035331726074\n",
      "epoch 25, batch 260, loss = 2.720754623413086\n",
      "epoch 25, batch 270, loss = 2.7599968910217285\n",
      "epoch 25, batch 280, loss = 2.674638032913208\n",
      "epoch 26, batch 0, loss = 2.6910226345062256\n",
      "epoch 26, batch 10, loss = 2.678128242492676\n",
      "epoch 26, batch 20, loss = 2.682267427444458\n",
      "epoch 26, batch 30, loss = 2.6722447872161865\n",
      "epoch 26, batch 40, loss = 2.6917459964752197\n",
      "epoch 26, batch 50, loss = 2.7057905197143555\n",
      "epoch 26, batch 60, loss = 2.7244415283203125\n",
      "epoch 26, batch 70, loss = 2.6712660789489746\n",
      "epoch 26, batch 80, loss = 2.6862192153930664\n",
      "epoch 26, batch 90, loss = 2.721344470977783\n",
      "epoch 26, batch 100, loss = 2.6625771522521973\n",
      "epoch 26, batch 110, loss = 2.658534288406372\n",
      "epoch 26, batch 120, loss = 2.654310464859009\n",
      "epoch 26, batch 130, loss = 2.6958961486816406\n",
      "epoch 26, batch 140, loss = 2.69980525970459\n",
      "epoch 26, batch 150, loss = 2.693089008331299\n",
      "epoch 26, batch 160, loss = 2.7210049629211426\n",
      "epoch 26, batch 170, loss = 2.686361789703369\n",
      "epoch 26, batch 180, loss = 2.636892557144165\n",
      "epoch 26, batch 190, loss = 2.7246594429016113\n",
      "epoch 26, batch 200, loss = 2.744999885559082\n",
      "epoch 26, batch 210, loss = 2.7257442474365234\n",
      "epoch 26, batch 220, loss = 2.700369119644165\n",
      "epoch 26, batch 230, loss = 2.6918997764587402\n",
      "epoch 26, batch 240, loss = 2.7093658447265625\n",
      "epoch 26, batch 250, loss = 2.671130657196045\n",
      "epoch 26, batch 260, loss = 2.7152888774871826\n",
      "epoch 26, batch 270, loss = 2.6718616485595703\n",
      "epoch 26, batch 280, loss = 2.7566208839416504\n",
      "epoch 27, batch 0, loss = 2.6434600353240967\n",
      "epoch 27, batch 10, loss = 2.707015037536621\n",
      "epoch 27, batch 20, loss = 2.693509817123413\n",
      "epoch 27, batch 30, loss = 2.6928603649139404\n",
      "epoch 27, batch 40, loss = 2.67441987991333\n",
      "epoch 27, batch 50, loss = 2.7052597999572754\n",
      "epoch 27, batch 60, loss = 2.7078676223754883\n",
      "epoch 27, batch 70, loss = 2.6632490158081055\n",
      "epoch 27, batch 80, loss = 2.7013132572174072\n",
      "epoch 27, batch 90, loss = 2.7476468086242676\n",
      "epoch 27, batch 100, loss = 2.6340532302856445\n",
      "epoch 27, batch 110, loss = 2.6941254138946533\n",
      "epoch 27, batch 120, loss = 2.7074432373046875\n",
      "epoch 27, batch 130, loss = 2.671233892440796\n",
      "epoch 27, batch 140, loss = 2.6693978309631348\n",
      "epoch 27, batch 150, loss = 2.6801624298095703\n",
      "epoch 27, batch 160, loss = 2.6781272888183594\n",
      "epoch 27, batch 170, loss = 2.7458837032318115\n",
      "epoch 27, batch 180, loss = 2.730706214904785\n",
      "epoch 27, batch 190, loss = 2.7229228019714355\n",
      "epoch 27, batch 200, loss = 2.6730189323425293\n",
      "epoch 27, batch 210, loss = 2.670447587966919\n",
      "epoch 27, batch 220, loss = 2.6925230026245117\n",
      "epoch 27, batch 230, loss = 2.6961629390716553\n",
      "epoch 27, batch 240, loss = 2.7412543296813965\n",
      "epoch 27, batch 250, loss = 2.6903700828552246\n",
      "epoch 27, batch 260, loss = 2.720787525177002\n",
      "epoch 27, batch 270, loss = 2.7240288257598877\n",
      "epoch 27, batch 280, loss = 2.6824593544006348\n",
      "epoch 28, batch 0, loss = 2.6341333389282227\n",
      "epoch 28, batch 10, loss = 2.7370269298553467\n",
      "epoch 28, batch 20, loss = 2.6590185165405273\n",
      "epoch 28, batch 30, loss = 2.684422016143799\n",
      "epoch 28, batch 40, loss = 2.6270713806152344\n",
      "epoch 28, batch 50, loss = 2.6762330532073975\n",
      "epoch 28, batch 60, loss = 2.6469309329986572\n",
      "epoch 28, batch 70, loss = 2.651979446411133\n",
      "epoch 28, batch 80, loss = 2.7116947174072266\n",
      "epoch 28, batch 90, loss = 2.678621768951416\n",
      "epoch 28, batch 100, loss = 2.732664108276367\n",
      "epoch 28, batch 110, loss = 2.694905996322632\n",
      "epoch 28, batch 120, loss = 2.6986210346221924\n",
      "epoch 28, batch 130, loss = 2.6970443725585938\n",
      "epoch 28, batch 140, loss = 2.6696557998657227\n",
      "epoch 28, batch 150, loss = 2.6711158752441406\n",
      "epoch 28, batch 160, loss = 2.6640877723693848\n",
      "epoch 28, batch 170, loss = 2.6877126693725586\n",
      "epoch 28, batch 180, loss = 2.6760644912719727\n",
      "epoch 28, batch 190, loss = 2.7111353874206543\n",
      "epoch 28, batch 200, loss = 2.6847927570343018\n",
      "epoch 28, batch 210, loss = 2.688218116760254\n",
      "epoch 28, batch 220, loss = 2.7112011909484863\n",
      "epoch 28, batch 230, loss = 2.7129390239715576\n",
      "epoch 28, batch 240, loss = 2.707156181335449\n",
      "epoch 28, batch 250, loss = 2.743931770324707\n",
      "epoch 28, batch 260, loss = 2.646677255630493\n",
      "epoch 28, batch 270, loss = 2.717744827270508\n",
      "epoch 28, batch 280, loss = 2.746734142303467\n",
      "epoch 29, batch 0, loss = 2.7457642555236816\n",
      "epoch 29, batch 10, loss = 2.7567901611328125\n",
      "epoch 29, batch 20, loss = 2.688697576522827\n",
      "epoch 29, batch 30, loss = 2.7089760303497314\n",
      "epoch 29, batch 40, loss = 2.6398401260375977\n",
      "epoch 29, batch 50, loss = 2.7007203102111816\n",
      "epoch 29, batch 60, loss = 2.6983132362365723\n",
      "epoch 29, batch 70, loss = 2.69964599609375\n",
      "epoch 29, batch 80, loss = 2.6646385192871094\n",
      "epoch 29, batch 90, loss = 2.6644482612609863\n",
      "epoch 29, batch 100, loss = 2.710050106048584\n",
      "epoch 29, batch 110, loss = 2.6890666484832764\n",
      "epoch 29, batch 120, loss = 2.6347031593322754\n",
      "epoch 29, batch 130, loss = 2.665332317352295\n",
      "epoch 29, batch 140, loss = 2.697819232940674\n",
      "epoch 29, batch 150, loss = 2.648876190185547\n",
      "epoch 29, batch 160, loss = 2.711256504058838\n",
      "epoch 29, batch 170, loss = 2.6518948078155518\n",
      "epoch 29, batch 180, loss = 2.6612861156463623\n",
      "epoch 29, batch 190, loss = 2.65488862991333\n",
      "epoch 29, batch 200, loss = 2.670186996459961\n",
      "epoch 29, batch 210, loss = 2.6725382804870605\n",
      "epoch 29, batch 220, loss = 2.6770529747009277\n",
      "epoch 29, batch 230, loss = 2.7335424423217773\n",
      "epoch 29, batch 240, loss = 2.6950650215148926\n",
      "epoch 29, batch 250, loss = 2.6882433891296387\n",
      "epoch 29, batch 260, loss = 2.7169060707092285\n",
      "epoch 29, batch 270, loss = 2.652369976043701\n",
      "epoch 29, batch 280, loss = 2.6703319549560547\n",
      "epoch 30, batch 0, loss = 2.652214765548706\n",
      "epoch 30, batch 10, loss = 2.662684679031372\n",
      "epoch 30, batch 20, loss = 2.647592067718506\n",
      "epoch 30, batch 30, loss = 2.697740077972412\n",
      "epoch 30, batch 40, loss = 2.6788220405578613\n",
      "epoch 30, batch 50, loss = 2.6455941200256348\n",
      "epoch 30, batch 60, loss = 2.6274402141571045\n",
      "epoch 30, batch 70, loss = 2.67030668258667\n",
      "epoch 30, batch 80, loss = 2.66933536529541\n",
      "epoch 30, batch 90, loss = 2.688246250152588\n",
      "epoch 30, batch 100, loss = 2.691676616668701\n",
      "epoch 30, batch 110, loss = 2.6796069145202637\n",
      "epoch 30, batch 120, loss = 2.704836368560791\n",
      "epoch 30, batch 130, loss = 2.6401262283325195\n",
      "epoch 30, batch 140, loss = 2.6597723960876465\n",
      "epoch 30, batch 150, loss = 2.725438117980957\n",
      "epoch 30, batch 160, loss = 2.6195569038391113\n",
      "epoch 30, batch 170, loss = 2.6491646766662598\n",
      "epoch 30, batch 180, loss = 2.605541229248047\n",
      "epoch 30, batch 190, loss = 2.730909824371338\n",
      "epoch 30, batch 200, loss = 2.6509995460510254\n",
      "epoch 30, batch 210, loss = 2.663735866546631\n",
      "epoch 30, batch 220, loss = 2.6689023971557617\n",
      "epoch 30, batch 230, loss = 2.6716413497924805\n",
      "epoch 30, batch 240, loss = 2.710496425628662\n",
      "epoch 30, batch 250, loss = 2.7259137630462646\n",
      "epoch 30, batch 260, loss = 2.669848680496216\n",
      "epoch 30, batch 270, loss = 2.6797189712524414\n",
      "epoch 30, batch 280, loss = 2.6939680576324463\n",
      "epoch 31, batch 0, loss = 2.652026653289795\n",
      "epoch 31, batch 10, loss = 2.7047274112701416\n",
      "epoch 31, batch 20, loss = 2.6603689193725586\n",
      "epoch 31, batch 30, loss = 2.6722230911254883\n",
      "epoch 31, batch 40, loss = 2.6673431396484375\n",
      "epoch 31, batch 50, loss = 2.674849033355713\n",
      "epoch 31, batch 60, loss = 2.6982505321502686\n",
      "epoch 31, batch 70, loss = 2.698918342590332\n",
      "epoch 31, batch 80, loss = 2.7033605575561523\n",
      "epoch 31, batch 90, loss = 2.7025837898254395\n",
      "epoch 31, batch 100, loss = 2.692045211791992\n",
      "epoch 31, batch 110, loss = 2.699141025543213\n",
      "epoch 31, batch 120, loss = 2.7710413932800293\n",
      "epoch 31, batch 130, loss = 2.7003986835479736\n",
      "epoch 31, batch 140, loss = 2.6602864265441895\n",
      "epoch 31, batch 150, loss = 2.683708667755127\n",
      "epoch 31, batch 160, loss = 2.694308280944824\n",
      "epoch 31, batch 170, loss = 2.6586251258850098\n",
      "epoch 31, batch 180, loss = 2.69701886177063\n",
      "epoch 31, batch 190, loss = 2.6550965309143066\n",
      "epoch 31, batch 200, loss = 2.662604331970215\n",
      "epoch 31, batch 210, loss = 2.697418451309204\n",
      "epoch 31, batch 220, loss = 2.7259039878845215\n",
      "epoch 31, batch 230, loss = 2.691920518875122\n",
      "epoch 31, batch 240, loss = 2.7128114700317383\n",
      "epoch 31, batch 250, loss = 2.714498996734619\n",
      "epoch 31, batch 260, loss = 2.6776926517486572\n",
      "epoch 31, batch 270, loss = 2.7011728286743164\n",
      "epoch 31, batch 280, loss = 2.6353542804718018\n",
      "epoch 32, batch 0, loss = 2.6786131858825684\n",
      "epoch 32, batch 10, loss = 2.632019519805908\n",
      "epoch 32, batch 20, loss = 2.636117935180664\n",
      "epoch 32, batch 30, loss = 2.6855673789978027\n",
      "epoch 32, batch 40, loss = 2.6350531578063965\n",
      "epoch 32, batch 50, loss = 2.690901756286621\n",
      "epoch 32, batch 60, loss = 2.7069242000579834\n",
      "epoch 32, batch 70, loss = 2.664393186569214\n",
      "epoch 32, batch 80, loss = 2.7195088863372803\n",
      "epoch 32, batch 90, loss = 2.667008876800537\n",
      "epoch 32, batch 100, loss = 2.6392877101898193\n",
      "epoch 32, batch 110, loss = 2.6378660202026367\n",
      "epoch 32, batch 120, loss = 2.6731038093566895\n",
      "epoch 32, batch 130, loss = 2.6706056594848633\n",
      "epoch 32, batch 140, loss = 2.700263023376465\n",
      "epoch 32, batch 150, loss = 2.7236790657043457\n",
      "epoch 32, batch 160, loss = 2.705576181411743\n",
      "epoch 32, batch 170, loss = 2.6681952476501465\n",
      "epoch 32, batch 180, loss = 2.7032270431518555\n",
      "epoch 32, batch 190, loss = 2.6394267082214355\n",
      "epoch 32, batch 200, loss = 2.6508822441101074\n",
      "epoch 32, batch 210, loss = 2.70527982711792\n",
      "epoch 32, batch 220, loss = 2.696812152862549\n",
      "epoch 32, batch 230, loss = 2.6439602375030518\n",
      "epoch 32, batch 240, loss = 2.660893440246582\n",
      "epoch 32, batch 250, loss = 2.618983745574951\n",
      "epoch 32, batch 260, loss = 2.670304298400879\n",
      "epoch 32, batch 270, loss = 2.6590888500213623\n",
      "epoch 32, batch 280, loss = 2.6429443359375\n",
      "epoch 33, batch 0, loss = 2.6481728553771973\n",
      "epoch 33, batch 10, loss = 2.606779098510742\n",
      "epoch 33, batch 20, loss = 2.587299346923828\n",
      "epoch 33, batch 30, loss = 2.694387435913086\n",
      "epoch 33, batch 40, loss = 2.6723365783691406\n",
      "epoch 33, batch 50, loss = 2.658579111099243\n",
      "epoch 33, batch 60, loss = 2.6407055854797363\n",
      "epoch 33, batch 70, loss = 2.650318145751953\n",
      "epoch 33, batch 80, loss = 2.719576358795166\n",
      "epoch 33, batch 90, loss = 2.7069640159606934\n",
      "epoch 33, batch 100, loss = 2.653292179107666\n",
      "epoch 33, batch 110, loss = 2.6507484912872314\n",
      "epoch 33, batch 120, loss = 2.706071376800537\n",
      "epoch 33, batch 130, loss = 2.648787498474121\n",
      "epoch 33, batch 140, loss = 2.65246319770813\n",
      "epoch 33, batch 150, loss = 2.698680877685547\n",
      "epoch 33, batch 160, loss = 2.7007110118865967\n",
      "epoch 33, batch 170, loss = 2.7146730422973633\n",
      "epoch 33, batch 180, loss = 2.6861627101898193\n",
      "epoch 33, batch 190, loss = 2.6349411010742188\n",
      "epoch 33, batch 200, loss = 2.6512603759765625\n",
      "epoch 33, batch 210, loss = 2.705573558807373\n",
      "epoch 33, batch 220, loss = 2.7001266479492188\n",
      "epoch 33, batch 230, loss = 2.6434953212738037\n",
      "epoch 33, batch 240, loss = 2.627755641937256\n",
      "epoch 33, batch 250, loss = 2.682579517364502\n",
      "epoch 33, batch 260, loss = 2.6938886642456055\n",
      "epoch 33, batch 270, loss = 2.639601707458496\n",
      "epoch 33, batch 280, loss = 2.672206401824951\n",
      "epoch 34, batch 0, loss = 2.5910167694091797\n",
      "epoch 34, batch 10, loss = 2.657068967819214\n",
      "epoch 34, batch 20, loss = 2.6622190475463867\n",
      "epoch 34, batch 30, loss = 2.6462535858154297\n",
      "epoch 34, batch 40, loss = 2.694901466369629\n",
      "epoch 34, batch 50, loss = 2.6628003120422363\n",
      "epoch 34, batch 60, loss = 2.6852707862854004\n",
      "epoch 34, batch 70, loss = 2.6793346405029297\n",
      "epoch 34, batch 80, loss = 2.664519786834717\n",
      "epoch 34, batch 90, loss = 2.652730941772461\n",
      "epoch 34, batch 100, loss = 2.658407688140869\n",
      "epoch 34, batch 110, loss = 2.6366066932678223\n",
      "epoch 34, batch 120, loss = 2.677537441253662\n",
      "epoch 34, batch 130, loss = 2.650421380996704\n",
      "epoch 34, batch 140, loss = 2.678166151046753\n",
      "epoch 34, batch 150, loss = 2.6354711055755615\n",
      "epoch 34, batch 160, loss = 2.66652774810791\n",
      "epoch 34, batch 170, loss = 2.7047605514526367\n",
      "epoch 34, batch 180, loss = 2.700779914855957\n",
      "epoch 34, batch 190, loss = 2.7055110931396484\n",
      "epoch 34, batch 200, loss = 2.677422046661377\n",
      "epoch 34, batch 210, loss = 2.708828926086426\n",
      "epoch 34, batch 220, loss = 2.6470348834991455\n",
      "epoch 34, batch 230, loss = 2.671563148498535\n",
      "epoch 34, batch 240, loss = 2.6737732887268066\n",
      "epoch 34, batch 250, loss = 2.6844544410705566\n",
      "epoch 34, batch 260, loss = 2.7199254035949707\n",
      "epoch 34, batch 270, loss = 2.6872334480285645\n",
      "epoch 34, batch 280, loss = 2.7341091632843018\n",
      "epoch 35, batch 0, loss = 2.6244027614593506\n",
      "epoch 35, batch 10, loss = 2.6952621936798096\n",
      "epoch 35, batch 20, loss = 2.605696439743042\n",
      "epoch 35, batch 30, loss = 2.683598518371582\n",
      "epoch 35, batch 40, loss = 2.623223304748535\n",
      "epoch 35, batch 50, loss = 2.622183084487915\n",
      "epoch 35, batch 60, loss = 2.6848597526550293\n",
      "epoch 35, batch 70, loss = 2.613154649734497\n",
      "epoch 35, batch 80, loss = 2.602168560028076\n",
      "epoch 35, batch 90, loss = 2.6084513664245605\n",
      "epoch 35, batch 100, loss = 2.6570615768432617\n",
      "epoch 35, batch 110, loss = 2.6373817920684814\n",
      "epoch 35, batch 120, loss = 2.671160936355591\n",
      "epoch 35, batch 130, loss = 2.620913505554199\n",
      "epoch 35, batch 140, loss = 2.683547019958496\n",
      "epoch 35, batch 150, loss = 2.665653944015503\n",
      "epoch 35, batch 160, loss = 2.639397144317627\n",
      "epoch 35, batch 170, loss = 2.6730926036834717\n",
      "epoch 35, batch 180, loss = 2.6787753105163574\n",
      "epoch 35, batch 190, loss = 2.651729106903076\n",
      "epoch 35, batch 200, loss = 2.667012929916382\n",
      "epoch 35, batch 210, loss = 2.6141202449798584\n",
      "epoch 35, batch 220, loss = 2.635592460632324\n",
      "epoch 35, batch 230, loss = 2.701232671737671\n",
      "epoch 35, batch 240, loss = 2.688154697418213\n",
      "epoch 35, batch 250, loss = 2.65578556060791\n",
      "epoch 35, batch 260, loss = 2.6903700828552246\n",
      "epoch 35, batch 270, loss = 2.683955192565918\n",
      "epoch 35, batch 280, loss = 2.653130054473877\n",
      "epoch 36, batch 0, loss = 2.5959668159484863\n",
      "epoch 36, batch 10, loss = 2.6336777210235596\n",
      "epoch 36, batch 20, loss = 2.6418089866638184\n",
      "epoch 36, batch 30, loss = 2.662755012512207\n",
      "epoch 36, batch 40, loss = 2.7031517028808594\n",
      "epoch 36, batch 50, loss = 2.698768138885498\n",
      "epoch 36, batch 60, loss = 2.6737632751464844\n",
      "epoch 36, batch 70, loss = 2.576503276824951\n",
      "epoch 36, batch 80, loss = 2.7066733837127686\n",
      "epoch 36, batch 90, loss = 2.6428403854370117\n",
      "epoch 36, batch 100, loss = 2.60195255279541\n",
      "epoch 36, batch 110, loss = 2.7049572467803955\n",
      "epoch 36, batch 120, loss = 2.6968116760253906\n",
      "epoch 36, batch 130, loss = 2.647749662399292\n",
      "epoch 36, batch 140, loss = 2.635333299636841\n",
      "epoch 36, batch 150, loss = 2.6916675567626953\n",
      "epoch 36, batch 160, loss = 2.634284019470215\n",
      "epoch 36, batch 170, loss = 2.6762208938598633\n",
      "epoch 36, batch 180, loss = 2.659419298171997\n",
      "epoch 36, batch 190, loss = 2.672499895095825\n",
      "epoch 36, batch 200, loss = 2.6386241912841797\n",
      "epoch 36, batch 210, loss = 2.7056095600128174\n",
      "epoch 36, batch 220, loss = 2.658792495727539\n",
      "epoch 36, batch 230, loss = 2.661092758178711\n",
      "epoch 36, batch 240, loss = 2.6669397354125977\n",
      "epoch 36, batch 250, loss = 2.651942491531372\n",
      "epoch 36, batch 260, loss = 2.643300771713257\n",
      "epoch 36, batch 270, loss = 2.6658878326416016\n",
      "epoch 36, batch 280, loss = 2.6572163105010986\n",
      "epoch 37, batch 0, loss = 2.6533803939819336\n",
      "epoch 37, batch 10, loss = 2.5930192470550537\n",
      "epoch 37, batch 20, loss = 2.6033501625061035\n",
      "epoch 37, batch 30, loss = 2.60646390914917\n",
      "epoch 37, batch 40, loss = 2.6440482139587402\n",
      "epoch 37, batch 50, loss = 2.647073984146118\n",
      "epoch 37, batch 60, loss = 2.633730411529541\n",
      "epoch 37, batch 70, loss = 2.668376922607422\n",
      "epoch 37, batch 80, loss = 2.6548376083374023\n",
      "epoch 37, batch 90, loss = 2.634535312652588\n",
      "epoch 37, batch 100, loss = 2.720919132232666\n",
      "epoch 37, batch 110, loss = 2.6001784801483154\n",
      "epoch 37, batch 120, loss = 2.6826059818267822\n",
      "epoch 37, batch 130, loss = 2.6484193801879883\n",
      "epoch 37, batch 140, loss = 2.675459384918213\n",
      "epoch 37, batch 150, loss = 2.6664743423461914\n",
      "epoch 37, batch 160, loss = 2.6844277381896973\n",
      "epoch 37, batch 170, loss = 2.637068271636963\n",
      "epoch 37, batch 180, loss = 2.6228456497192383\n",
      "epoch 37, batch 190, loss = 2.65826678276062\n",
      "epoch 37, batch 200, loss = 2.711839199066162\n",
      "epoch 37, batch 210, loss = 2.691877841949463\n",
      "epoch 37, batch 220, loss = 2.6530816555023193\n",
      "epoch 37, batch 230, loss = 2.6827354431152344\n",
      "epoch 37, batch 240, loss = 2.6563150882720947\n",
      "epoch 37, batch 250, loss = 2.6541318893432617\n",
      "epoch 37, batch 260, loss = 2.6384220123291016\n",
      "epoch 37, batch 270, loss = 2.683915853500366\n",
      "epoch 37, batch 280, loss = 2.618847131729126\n",
      "epoch 38, batch 0, loss = 2.636820077896118\n",
      "epoch 38, batch 10, loss = 2.603858470916748\n",
      "epoch 38, batch 20, loss = 2.635895252227783\n",
      "epoch 38, batch 30, loss = 2.649491786956787\n",
      "epoch 38, batch 40, loss = 2.6816365718841553\n",
      "epoch 38, batch 50, loss = 2.6152284145355225\n",
      "epoch 38, batch 60, loss = 2.628020763397217\n",
      "epoch 38, batch 70, loss = 2.6113357543945312\n",
      "epoch 38, batch 80, loss = 2.5872669219970703\n",
      "epoch 38, batch 90, loss = 2.6457502841949463\n",
      "epoch 38, batch 100, loss = 2.6298539638519287\n",
      "epoch 38, batch 110, loss = 2.665484666824341\n",
      "epoch 38, batch 120, loss = 2.6508936882019043\n",
      "epoch 38, batch 130, loss = 2.653151035308838\n",
      "epoch 38, batch 140, loss = 2.6971654891967773\n",
      "epoch 38, batch 150, loss = 2.601087808609009\n",
      "epoch 38, batch 160, loss = 2.657102584838867\n",
      "epoch 38, batch 170, loss = 2.662909984588623\n",
      "epoch 38, batch 180, loss = 2.625333070755005\n",
      "epoch 38, batch 190, loss = 2.6704463958740234\n",
      "epoch 38, batch 200, loss = 2.658078670501709\n",
      "epoch 38, batch 210, loss = 2.6434669494628906\n",
      "epoch 38, batch 220, loss = 2.6172096729278564\n",
      "epoch 38, batch 230, loss = 2.6611533164978027\n",
      "epoch 38, batch 240, loss = 2.6028833389282227\n",
      "epoch 38, batch 250, loss = 2.5710906982421875\n",
      "epoch 38, batch 260, loss = 2.706996440887451\n",
      "epoch 38, batch 270, loss = 2.6607108116149902\n",
      "epoch 38, batch 280, loss = 2.5840513706207275\n",
      "epoch 39, batch 0, loss = 2.60996150970459\n",
      "epoch 39, batch 10, loss = 2.5883941650390625\n",
      "epoch 39, batch 20, loss = 2.6327338218688965\n",
      "epoch 39, batch 30, loss = 2.7129416465759277\n",
      "epoch 39, batch 40, loss = 2.623948097229004\n",
      "epoch 39, batch 50, loss = 2.5935935974121094\n",
      "epoch 39, batch 60, loss = 2.683990955352783\n",
      "epoch 39, batch 70, loss = 2.647191047668457\n",
      "epoch 39, batch 80, loss = 2.6555778980255127\n",
      "epoch 39, batch 90, loss = 2.656914234161377\n",
      "epoch 39, batch 100, loss = 2.636319637298584\n",
      "epoch 39, batch 110, loss = 2.59450101852417\n",
      "epoch 39, batch 120, loss = 2.6184070110321045\n",
      "epoch 39, batch 130, loss = 2.6516294479370117\n",
      "epoch 39, batch 140, loss = 2.6136996746063232\n",
      "epoch 39, batch 150, loss = 2.626023292541504\n",
      "epoch 39, batch 160, loss = 2.6446502208709717\n",
      "epoch 39, batch 170, loss = 2.631577730178833\n",
      "epoch 39, batch 180, loss = 2.6749212741851807\n",
      "epoch 39, batch 190, loss = 2.627418041229248\n",
      "epoch 39, batch 200, loss = 2.650027275085449\n",
      "epoch 39, batch 210, loss = 2.6638007164001465\n",
      "epoch 39, batch 220, loss = 2.605695962905884\n",
      "epoch 39, batch 230, loss = 2.6332690715789795\n",
      "epoch 39, batch 240, loss = 2.6320300102233887\n",
      "epoch 39, batch 250, loss = 2.6467599868774414\n",
      "epoch 39, batch 260, loss = 2.6225008964538574\n",
      "epoch 39, batch 270, loss = 2.6192221641540527\n",
      "epoch 39, batch 280, loss = 2.6842217445373535\n",
      "epoch 40, batch 0, loss = 2.58522367477417\n",
      "epoch 40, batch 10, loss = 2.6216623783111572\n",
      "epoch 40, batch 20, loss = 2.626371383666992\n",
      "epoch 40, batch 30, loss = 2.6752333641052246\n",
      "epoch 40, batch 40, loss = 2.6164767742156982\n",
      "epoch 40, batch 50, loss = 2.6283926963806152\n",
      "epoch 40, batch 60, loss = 2.6422195434570312\n",
      "epoch 40, batch 70, loss = 2.6390879154205322\n",
      "epoch 40, batch 80, loss = 2.603898286819458\n",
      "epoch 40, batch 90, loss = 2.6463842391967773\n",
      "epoch 40, batch 100, loss = 2.6249594688415527\n",
      "epoch 40, batch 110, loss = 2.6028504371643066\n",
      "epoch 40, batch 120, loss = 2.681757688522339\n",
      "epoch 40, batch 130, loss = 2.6771903038024902\n",
      "epoch 40, batch 140, loss = 2.62247896194458\n",
      "epoch 40, batch 150, loss = 2.6573452949523926\n",
      "epoch 40, batch 160, loss = 2.623777389526367\n",
      "epoch 40, batch 170, loss = 2.5883398056030273\n",
      "epoch 40, batch 180, loss = 2.6018192768096924\n",
      "epoch 40, batch 190, loss = 2.663947582244873\n",
      "epoch 40, batch 200, loss = 2.6503920555114746\n",
      "epoch 40, batch 210, loss = 2.7179837226867676\n",
      "epoch 40, batch 220, loss = 2.656332492828369\n",
      "epoch 40, batch 230, loss = 2.673553228378296\n",
      "epoch 40, batch 240, loss = 2.6693222522735596\n",
      "epoch 40, batch 250, loss = 2.644256353378296\n",
      "epoch 40, batch 260, loss = 2.659317970275879\n",
      "epoch 40, batch 270, loss = 2.6677727699279785\n",
      "epoch 40, batch 280, loss = 2.6444077491760254\n",
      "Training time: 642.1370658874512\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "\n",
    "device = torch.device(\"cuda\")  # 或者 \"cpu\"\n",
    "\n",
    "train = dat  # 你的训练数据\n",
    "n = len(train)\n",
    "n_hidden = 256\n",
    "nepoch = 41\n",
    "bs = 256\n",
    "\n",
    "lstm = MyLSTM(charset_size, n_hidden).to(device)\n",
    "opt = torch.optim.Adam(lstm.parameters(), lr=0.001)\n",
    "lossfn = nn.NLLLoss(reduction=\"none\")\n",
    "\n",
    "train_ind = np.arange(n)\n",
    "losses = []\n",
    "\n",
    "t1 = time.time()\n",
    "for k in range(nepoch):\n",
    "    np.random.shuffle(train_ind)\n",
    "    for j in range(0, n, bs):\n",
    "        ind = train_ind[j:(j + bs)]\n",
    "        mb = [train[i] for i in ind]\n",
    "        mb_size = len(mb)\n",
    "        input, actual_len, target = names2tensor(mb)\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        max_len = input.shape[0]\n",
    "        hidden = lstm.init_hidden(mb_size)\n",
    "        hidden = (hidden[0].to(device), hidden[1].to(device))\n",
    "\n",
    "        loss = 0.0\n",
    "        for s in range(max_len):\n",
    "            output, hidden = lstm(input[s], hidden)\n",
    "            loss_s = lossfn(output, target[s])\n",
    "            valid = torch.tensor((s < actual_len).astype(int)).to(device)\n",
    "            loss = loss + loss_s * valid\n",
    "        loss = torch.mean(loss / torch.tensor(actual_len).to(device))\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        if (j // bs) % 10 == 0:\n",
    "            print(f\"epoch {k}, batch {j // bs}, loss = {loss.item()}\")\n",
    "t2 = time.time()\n",
    "print(\"Training time:\", t2 - t1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b60bc022-62e8-423a-b123-4c89610bb318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLSTM(\n",
       "  (i2f): Linear(in_features=307, out_features=256, bias=True)\n",
       "  (i2i): Linear(in_features=307, out_features=256, bias=True)\n",
       "  (i2o): Linear(in_features=307, out_features=256, bias=True)\n",
       "  (i2g): Linear(in_features=307, out_features=256, bias=True)\n",
       "  (out_layer): Linear(in_features=256, out_features=51, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (logsoftmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型参数\n",
    "torch.save(lstm.state_dict(), \"gen_en_lstm.pt\")\n",
    "\n",
    "# 加载模型参数\n",
    "lstm.load_state_dict(torch.load(\"gen_en_lstm.pt\", map_location=device))\n",
    "\n",
    "# 设置模型为评估模式\n",
    "lstm.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4b13f8b-7447-4460-853e-0059ce20d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_name_lstm(max_len=4):\n",
    "    lstm.eval()\n",
    "    family_name = random_family_name()\n",
    "    input = char2tensor(family_name).to(device)\n",
    "    char_ind = [torch.argmax(input).item()]\n",
    "    hidden = lstm.init_hidden(batch_size=1)\n",
    "    hidden = (hidden[0].to(device), hidden[1].to(device))\n",
    "\n",
    "    for _ in range(max_len - 1):\n",
    "        output, hidden = lstm(input, hidden)\n",
    "        ind = torch.argmax(output).item()\n",
    "        if ind == charset_size - 1:  # <END>\n",
    "            break\n",
    "        char_ind.append(ind)\n",
    "        input.zero_()\n",
    "        input[0, ind] = 1.0\n",
    "    return char_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98e0df6b-8de1-44ed-95e6-46b2a1df1337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['雷斯塔尼奥' '伊尔贝' '瓦尔德拉' '耶尔维' '西尔韦斯特里' '布拉西尼' '库尔蒂'\n",
      " '迪亚科' '拉斯特里' '罗斯塔' '维尔德' '马尔科利尼' '埃斯特拉蒂耶' '维尔德'\n",
      " '韦尔纳' '维尔德' '马尔科利尼' '格拉迪斯拉夫' '库尔蒂' '尔科' '萨尔瓦尼'\n",
      " '维尔德' '巴尔达奇' '内斯特' '克拉斯特' '伊尔贝' '德拉斯特' '诺尔贝'\n",
      " '伊尔贝' '德拉斯特' '马尔科利尼' '勒夫' '达尔贝' '莱斯特拉' '瓦尔德拉'\n",
      " '西尔韦斯特里' '罗斯塔' '托尔托拉' '米尔科夫斯基' '特里亚诺' '耶尔维'\n",
      " '罗斯塔' '奇科尼' '贝尔托利' '克拉斯特' '迪亚科' '利亚诺' '亚尔马'\n",
      " '塔尔塔' '耶尔维']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "names = []\n",
    "for i in range(50):\n",
    "    ind = random_name_lstm(max_len=10)\n",
    "    names.append(\"\".join([dict[i] for i in ind]))\n",
    "\n",
    "np.set_printoptions(linewidth=50)\n",
    "print(np.array(names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (E:\\DL\\deeplearning)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
